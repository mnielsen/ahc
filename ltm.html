<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta charset="utf-8">
    <meta name="citation_title" content="Augmenting Long-term Memory">
    <meta name="citation_author" content="Nielsen, Michael">
    <meta name="citation_publication_date" content="2018">
    <meta name="citation_fulltext_html_url" content="http://augmentingcognition.com/XXX">
    <meta name="citation_fulltext_world_readable" content="">

    <title>Augmenting Long-term Memory</title>
    <link rel="stylesheet" type="text/css" href="style.css">
  </head>

  <body>
    <div id="header">
      <h1>Augmenting Long-term Memory</h1>
      <p>
	<a href="http://michaelnielsen.org">Michael Nielsen</a> &nbsp;
	| &nbsp; <a href="https://ycr.org">Y Combinator Research</a> &nbsp;
	| &nbsp; July 2018
      </p>
    </div>

    <div id="container">
      
      <span id="sidebar">
  <a href="index.html">How to Augment Human Cognition?</a><br>
  How to Invent New Primitives of Thought<br>
  <a href="ltm.html">Augmenting Long-term Memory</a><br>
  Toward a Young Lady's Illustrated Primer<br>
  Using Personal Memory Systems to Understand Mathematics<br>
  The Humane Use of Augmentation<br>
  <br>
  <strong>Resources</strong><br>
  <a href="https://twitter.com/michael_nielsen">Michael Nielsen on Twitter</a><br>
  <a href="http://eepurl.com/0Xxjb">Michael Nielsen's project announcement mailing list</a><br>
  <a href="http://cognitivemedium.com">cognitivemedium.com</a><br>
  <hr>
  <a href="http://michaelnielsen.org"><img src="assets/Michael_Nielsen_Web_Small.jpg" width="160px" style="border-style: none;"/></a><br>
  By <a href="http://michaelnielsen.org">Michael Nielsen</a></br>

</span>

      
    <p>
      One day in the mid-1920s, a Moscow newspaper reporter named
      Solomon Shereshevsky entered the laboratory of the psychologist
      Alexander Luria. Shereshevsky explained to Luria that his boss
      at the newspaper was surprised he didn't need to take any notes,
      but somehow still remembered all he was told, and had suggested
      he get his memory checked.
    </p>

    <p>
      Luria began testing Shereshevsky's memory. He began with simple
      tests, short strings of words and of numbers. Shereshevsky
      remembered these with ease, and so Luria gradually increased the
      length of the strings. But no matter how long they got,
      Shereshevsky could recite them back.  Fascinated, Luria went on
      to study Shereshevsky's memory for the next 30 years.  In a book
      summing up his research*<span class="marginnote">* Alexander
      Luria, &ldquo;The Mind of a Mnemonist&rdquo;, Harvard University
      Press (1968).</span>, Luria reported that:
    </p>

    <blockquote>
      [I]t appeared that there was no limit either to
      the <em>capacity</em> of S.'s memory or to the <em>durability of
      the traces he retained</em>. Experiments indicated that he had
      no difficulty reproducing any lengthy series of words whatever,
      even though these had originally been presented to him a week, a
      month, a year, or even many years earlier. In fact, some of
      these experiments designed to test his retention were performed
      (without his being given any warning) fifteen or sixteen years
      after the session in which he had originally recalled the
      words. Yet invariably they were successful.
    </blockquote>
      
    <p>
      Such stories are fascinating. Memory is fundamental to our
      thinking, and there is something seductive about the notion of
      having a perfect memory.  At the same time, many people feel
      ambivalent about their own memory. I've often heard people say
      &ldquo;I don't have a very good memory&rdquo;, sometimes
      sheepishly, sometimes apologetically, sometimes even defiantly.
    </p>

    <p>
      Given how central memory is to our thinking, it's natural to ask
      whether computers can somehow be used as tools to help improve
      our memory. This question turns out to be highly generative of
      good new ideas: indeed, pursuing it has led to many of the most
      important vision documents in the history of computing. One
      early example was Vannevar Bush's 1945
      proposal*<span class="marginnote">* Vannevar
      Bush, <a href="https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/">As
      We May Think</a>, The Atlantic (1945).</span> for a mechanical
      memory extender, the memex. Bush wrote:
    </p>

    <blockquote>
      A memex is a device in which an individual stores all his books,
      records, and communications, and which is mechanized so that it
      may be consulted with exceeding speed and flexibility. It is an
      enlarged intimate supplement to his memory.
    </blockquote>

    <p>
      The memex vision inspired many later computer pioneers,
      including Douglas Engelbart's ideas about augmentation, Ted
      Nelson's ideas about hypertext, and, indirectly, Tim
      Berners-Lee's conception of the world wide
      web*<span class="marginnote">* See, for example: Douglas
      Engelbart, <a href="XXX">Augmenting Human Intellect</a> (1962);
      Ted Nelson, XXX; and Tim
      Berners-Lee, <a href="https://w3.org/History/1989/proposal.html">Information
      Management: a Proposal</a> (1989).</span>. In his proposal for
      the web, Berners-Lee describes the need for his employer (the
      particle physics organization CERN) to develop a kind of
      collective institutional memory,
    </p>

    <blockquote>
      a pool of information to develop which could grow and evolve
      with the organization and the projects it describes.
    </blockquote>


    <p>
      These are just a few of the many attempts made to use computers
      to augment human memory. From the memex to the web to wikis to
      <a href="https://orgmode.org/">org-mode</a>
      to <a href="https://en.wikipedia.org/wiki/Project_Xanadu">Project
      Xanadu</a> to attempts
      to <a href="https://users.speakeasy.net/~lion/nb/book.pdf">make
      a map of every thought a person thinks</a>: the augmentation of
      memory has been an extremely generative vision for computing.
    </p>

    <p>
      In this essay we investigate personal memory systems, that is,
      systems designed to improve the long-term memory of a single
      person. I begin by describing my personal experience using such
      a system, and distill a set of principles governing good use of
      such systems. As we'll see, such systems can make memory
      a <em>choice</em>, rather than a haphazard event, to be left to
      chance.  I survey the cognitive science behind such systems, and
      argue that enhancing memory is central to augmenting human
      cognition. This essay also serves as background for
      a <a href="XXX">further essay</a>, which describes a vision for
      an active learning environment, which uses these ideas to raise
      the ceiling on the difficulty of material people can learn.
    </p>

    <h2>An example personal memory system: Anki</h2>

    <p>
      I'll begin with an account of my own experience with a personal
      memory system
      named <a href="https://apps.ankiweb.net/">Anki</a>*<span class="marginnote">*
      I've no affiliation at all with Anki. Other similar systems
      include <a href="https://mnemosyne-proj.org">Mnemosyne</a>
      and <a href="https://supermemo.com">SuperMemo</a>. My limited
      use suggests Mnemosyne is very similar to Anki.  SuperMemo runs
      only on Windows, and I haven't had an opportunity to use it,
      though I have been influenced by essays on
      the <a href="https://supermemo.com">SuperMemo website</a>. As
      will become clear, these systems are powerful, and the early
      parts of this essay will sound like an enthusiastic sales
      pitch. Later, we'll discuss some shortcomings, and room for
      improvement.</span>. At first glance, Anki seems nothing more
      than a computerized flashcard program. You enter a question:
    </p>

   <img src="assets/Anki_question.png">

    <p>
      And a corresponding answer:
    </p>

    <img src="assets/Anki_answer.png">

    <p>
      Later you'll be asked to review the card: that is, shown the
      question, and asked whether you know the answer or not.
    </p>

    <p>
      What makes Anki better than conventional flashcards is that it
      manages the review schedule. If you can answer a question
      correctly, the time interval between reviews gradually
      expands. So a one-day gap between reviews becomes two days, then
      six days, then a fortnight, and so on. The idea is that the
      information is becoming more firmly embedded in your memory, and
      so requires less frequent review. But if you ever miss an
      answer, the schedule resets, and you again have to build up the
      time interval between reviews.
    </p>

    <p>
      While it's obviously useful that the computer manages the
      interval between reviews, it perhaps doesn't seem like that big
      a deal.  The punchline is that this turns out to be
      a <em>vastly</em> more efficient way to remember information.
    </p>

    <p>
      How much more efficient?
    </p>

    <p>
      To answer that question, let's do some rough time estimates.  On
      average, it takes me about 8 seconds to review a card. Suppose I
      was using conventional flashcards, and reviewing them (say) once
      a week. If I wanted to remember something for the next 20 years,
      I'd need 20 years times 52 weeks per year times 8 seconds per
      card. That works out to a total review time of just over 2 hours
      for each card.
    </p>

    <p>
      By contrast, Anki's ever-expanding review intervals quickly rise
      past a month and then out past a year. Indeed, for my personal
      set of Anki cards the average interval between reviews is
      currently 1.2 years, and rising.  In
      an <a href="#Anki_analysis">appendix</a> below I estimate that
      for an average card, I'll only need 4 to 7 minutes of total
      review time over the entire 20 years.  Those estimates allow for
      occasional failed reviews, resetting the time interval.  That's
      a factor of more than 20 in savings over the more than 2 hours
      required with conventional flashcards!
    </p>

    <p>
      I therefore have two rules of thumb. First, if memorizing a fact
      seems worth 10 minutes of my time in the future, then I do
      it*<span class="marginnote">* I first saw an analysis along
      these lines in Gwern Branwen's review of spaced repetition:
      Gwern
      Branwen, <a href="https://www.gwern.net/Spaced-repetition">Spaced-Repetition</a>. His
      numbers are slightly more optimistic than mine &ndash; he
      arrives at a 5-minute rule of thumb, rather than 10 &ndash; but
      broadly consistent.</span>. Second, and superseding the first,
      if a fact seems striking then into Anki it goes, regardless of
      whether it seems worth 10 minutes of my future time or not. The
      reason for the exception is that many of the most important
      things we know are things we're not sure are going to be
      important, but which our intuitions tell us matter. This doesn't
      mean we should memorize everything. But it's worth cultivating
      taste in what to memorize.
    </p>

    <p>
      The single biggest change that Anki brings about is that it
      means memory is no longer a haphazard event, to be left to
      chance. Rather, it guarantees I will remember something, with
      minimal effort. That is, Anki <em>makes memory a choice</em>.
      This fact is, as we shall see, transformative.
    </p>

    <p>
      What can Anki be used for? I use Anki in all parts of my
      life. Professionally, I use it to learn from papers and books;
      to learn from talks and conferences; to help recall interesting
      things learned in conversation; and to remember key observations
      made while doing my everyday work. Personally, I use it to
      remember all kinds of facts relevant to my family and social
      life; about my city and travel; and about my hobbies. In later
      sections of the essay I will describe some of the most useful
      patterns, and patterns to avoid.
    </p>

    <p>
      I've used Anki to create roughly 11,000 cards over about 2 and a
      half years of regular use. That includes a 7-month break when I
      made very few new cards. When I'm keeping up with my card
      review, it takes about 15 to 20 minutes per day. If it routinely
      rises to much more than 20 minutes it usually means I'm adding
      cards too rapidly, and need to slow down. Alternately, it
      sometimes means I'm behind on my card review, of which more
      below.
    </p>

    <p>
      At a practical level, I use the desktop Anki client for entering
      new cards, and the mobile client*<span class="marginnote">* The
      desktop client is free, but the mobile client is, at the time of
      writing, 25 dollars.  Many people balk at that as &ldquo;too
      expensive&rdquo;. Personally, I've found the value is several
      orders of magnitude beyond that. Anki is probably more valuable
      to me than a car would be, and it's certainly worth more than a
      days' rent or a restaurant meal, both of which would usually
      exceed 25 dollars in my home city of San Francisco.</span> for
      reviewing. I review my Anki cards while walking to get my
      morning coffee, while waiting in line, on transit, and so on. I
      find it meditative.
    </p>

    <p>
      I had trouble getting started with Anki. Several acquaintances
      highly recommended it, and over the years I made multiple
      attempts to use it, each time quickly abandoning the attempt. In
      retrospect, there are substantial barriers to get over if you
      want to make it a habit.
    </p>

    <p>
      What made Anki finally &ldquo;take&rdquo; for me, turning it
      into a habit, was a project I took on as a joke. I'd been
      frustrated for years at never really learning the Unix command
      line. I'd only ever learned the most basic commands. Learning
      the command line is a superpower for people who program, so it
      seemed highly desirable to know well. So, for fun, I wondered if
      it might be possible to use Anki to essentially completely
      memorize a (short!) book about the Unix command line.
    </p>

    <p>
      It was!
    </p>

    <p>
      I chose O'Reilly Media's &ldquo;Macintosh Terminal Pocket
      Guide&rdquo;, by Daniel Barrett. I don't mean I literally
      memorized the entire text of the book. But I did memorize much
      of the conceptual knowledge in the book, as well as the names
      and syntax and options for most of the commands in the book. The
      exceptions were things I had no frame of reference to imagine
      using. But I did memorize most things I could imagine using. In
      the end I covered perhaps 70 percent of the book, skipping or
      skimming some sections that didn't seem relevant to me. Still,
      my knowledge of the command line increased enormously.
    </p>

    <p>
      Choosing this somewhat ludicrous, albeit extremely useful, goal
      gave me a great deal of confidence in Anki. It was extremely
      exciting, making it obvious that Anki would make it easy to
      learn things that would formerly have been quite difficult.
      This confidence, in turn, made it much easier to build an Anki
      habit.
    </p>

    <p>
      Doing this project also helped me learn the Anki interface and
      to experiment with different ways of posing questions. That is,
      I was building the skills necessary to use Anki well. Now,
      attaining basic Anki proficiency isn't especially difficult. But
      it is nonetheless a barrier to use, and having a really
      motivating project helped me get over that barrier.
    </p>


    <h3>Using Anki to thoroughly read a research paper in an
    unfamiliar field</h3>

    <p>
      I find Anki helpful for reading research papers, particularly in
      fields outside my expertise. As an example of how this can work,
      I'll describe my experience reading a 2016
      paper*<span class="marginnote">* David Silver, Aja Huang, Chris
      J. Maddison, Arthur Guez <em>et
      al</em>, <a href="assets/Silver2016a.pdf">Mastering the game of
      Go with deep neural networks and tree search</a>, Nature
      (2016).</span> describing AlphaGo, the computer system from
      Google DeepMind that beat some of the world's strongest players
      of the game Go.
    </p>

    <p>
      After the match where AlphaGo beat Lee Sedol, one of the
      strongest human Go players in history, I suggested
      to <a href="https://www.quantamagazine.org/">Quanta Magazine</a>
      that I write an article for them about the
      system*<span class="marginnote">* Michael
      A. Nielsen, <a href="https://www.quantamagazine.org/is-alphago-really-such-a-big-deal-20160329/">Is
      AlphaGo Really Such a Big Deal?</a>, Quanta
      (2016).</span>. AlphaGo was a hot media topic at the time, and
      the most common angle in stories was human interest, viewing
      AlphaGo as part of a long-standing human-versus-machine
      narrative, with a few technical details filled in, mostly as
      color.</p>

    <p>
      For my article, I had a different angle. Through the 1990s and
      first decade of the 2000s, I believed human-or-better general
      artificial intelligence was far away. The reason was that over
      that time researchers made only slow progress building systems
      to do intuitive pattern matching, of the kind that underlies
      human cognition in areas such as human vision and human speech
      recognition, as well as in playing games such as Go. Despite
      enormous effort by AI researchers, many pattern-matching feats
      which humans find effortless remained impossible for machines.
    </p>

    <p>
      While we made only very slow progress on this set of problems
      for a long time, around 2011 progress began to speed up, driven
      by advances in deep neural networks. For instance, machine
      vision systems rapidly went from being hopeless to being
      comparable to human beings for certain tasks.  By the time
      AlphaGo was released, it was no longer correct to say we had no
      idea how to build computer systems to do intuitive pattern
      matching. While we hadn't yet nailed the problem, we were making
      rapid progress. AlphaGo was a big part of that story, and I
      wanted my article to explore this notion of building computer
      systems to capture human intuition.
    </p>

    <p>
      While excited, writing such an article was going to be
      difficult. It was going to require a deeper understanding of the
      technical details of AlphaGo than a typical journalistic
      article. Fortunately, I knew a fair amount about the general
      area of neural networks &ndash; I'd written a book about
      them*<span class="marginnote">* Michael
      A. Nielsen, <a href="http://neuralnetworksanddeeplearning.com">"Neural
      Networks and Deep Learning"</a>, Determination Press
      (2015).</span>. But I knew nothing about the game Go, or about
      many of the ideas used by AlphaGo, based on a field known as
      reinforcement learning. I was going to need to learn this
      material from scratch, and to write a good article I was going
      to need to really understand the underlying technical material.
    </p>

    <p>
      Here's how I went about it.
    </p>

    <p>
      I began with the
      AlphaGo <a href="assets/Silver2016a.pdf">paper</a> itself. I
      began reading it quickly, almost skimming. I wasn't looking for
      a comprehensive understanding. Rather, I was doing two
      things. One, I was trying to simply identify the most important
      ideas in the paper. What were the names of the key techniques
      I'd need to learn about? Second, there was a kind of hoovering
      process, looking for basic facts that I could understand easily,
      and that would obviously benefit me. Things like basic
      terminology, the rules of Go, and so on.
    </p>

    <p>
      Here's a few examples of the kind of question I entered into
      Anki at this stage: &ldquo;What's the size of a Go
      board?&rdquo;; &ldquo;Who plays first in Go?&rdquo;; &ldquo;How
      many human training games did AlphaGo learn from?&rdquo;;
      &ldquo;Where did AlphaGo get its training data?&rdquo;;
      &ldquo;What were the names of the two main types of neural
      network AlphaGo used?&rdquo;
    </p>

    <p>
      As you can see, these are all elementary questions.  They're the
      kind of thing that are very easily picked up during an initial
      pass over the paper, with occasional digressions to search
      Google and Wikipedia, and so on. Furthermore, while these facts
      were easy to pick up in isolation, they also seemed likely to be
      useful in building a deeper understanding of other material in
      the paper.
    </p>

    <p>
      I made several rapid passes over the paper in this way, each
      time getting deeper and deeper. At this stage I wasn't trying to
      obtain anything like a complete understanding of
      AlphaGo. Rather, I was trying to build up my background
      understanding.  At all times, if something wasn't easy to
      understand, I didn't worry about it, I just keep moving. But
      over time, the range of things that were easy to understand grew
      and grew. I found myself adding questions about the types of
      features used as inputs to AlphaGo's neural networks, basic
      facts about the structure of the networks, and so on.
    </p>

    <p>
      After five or six such passes over the paper, I went back and
      attempted a thorough read. This time the purpose was to
      understand AlphaGo in detail.  By now I understood much of the
      background context, and it was relatively easy to do a thorough
      read, certainly far easier than coming into the paper
      cold. Don't get me wrong: it was still challenging. But it was
      far easier than it would have been otherwise.
    </p>

    <p>
      After doing one thorough pass over the AlphaGo paper, I made a
      second thorough pass, in a similar vein. Yet more fell into
      place. By this time, I understood the AlphaGo system well. Many
      of the questions I was putting into Anki were high level, and in
      some cases suggested further research directions. I certainly
      understood AlphaGo well enough that I was confident I could
      write the sections of my article dealing with it. (In practice,
      my article ranged over several systems, not just AlphaGo, and I
      had to learn about those as well, using a similar process,
      though I didn't go as deep.) I continued to add questions as I
      wrote my article, ending up adding perhaps 400-500 questions in
      total. But by this point the hardest work had been done.
    </p>

    <p>
      The entire process took a few days of my time, spread over a
      couple of weeks. That's a lot of work, but it also meant that
      I'd gone into a relatively unfamiliar technical area, and
      emerged with a reasonably thorough understanding of an
      outstanding recent research result in that area. With a little
      more work, I expect I would have begun having original research
      ideas in the area. In that sense, I got a large payoff for
      relatively little effort.
    </p>
      
    <p>
      Of course, instead of using Anki I could have taken conventional
      notes, using a similar process to build up an understanding of
      the paper. But using Anki gave me confidence I would retain much
      of the understanding over the long term.  A year or so later
      DeepMind released papers describing followup systems, known as
      AlphaGo Zero and AlphaZero*<span class="marginnote">* For
      AlphaGo Zero, see: David Silver, Julian Schrittwieser, Karen
      Simonyan, Ioannis Antonoglou <em>et
      al</em>, <a href="assets/Silver2017a.pdf">Mastering the game of
      Go without human knowledge</a>, Nature (2017). For AlphaZero,
      see: David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis
      Antonoglou <em>et
      al</em>, <a href="https://arxiv.org/abs/1712.01815">Mastering
      Chess and Shogi by Self-Play with a General Reinforcement
      Learning Algorithm</a> (2017).</span>. Despite the fact that I'd
      thought little about AlphaGo or reinforcement learning in the
      intervening time, I found I could read those followup papers
      with ease. While I didn't attempt to understand those papers as
      thoroughly as the initial AlphaGo paper, I found I could get a
      pretty good understanding of the papers in less than hour. I'd
      retained much of my earlier understanding!
    </p>

    <p>
      By contrast, had I used conventional note-taking in my original
      reading of the AlphaGo paper, my understanding would have
      rapidly evaporated, and it would have taken much longer to read
      the later papers. And so using Anki in this way gives confidence
      you will retain understanding over the long term. This
      confidence, in turn, makes the initial act of understanding more
      pleasurable, since you believe you're learning something for the
      long haul, not something you'll forget in a day or a week.
    </p>

    <p>
      Overall, this process gave me a reasonable grounding in modern
      deep reinforcement learning. This is an immensely important
      field, of great use in robotics, and many researchers believe it
      will play an important role in achieving general artificial
      intelligence. With a few days work I'd gone from knowing nothing
      about deep reinforcement learning to a durable understanding of
      a key paper in the field, a paper that made use of many
      techniques that were used across the entire field. Of course, I
      was still a long way from being an expert.  There were many
      important details about AlphaGo I hadn't understood, and I would
      have had to do far more work to build my own system in the area.
      But this foundational kind of understanding is a good basis on
      which to build deeper expertise.
    </p>

      <p>
	It's notable that I was reading the AlphaGo paper in support
	of a creative project of my own, namely, writing an article
	for Quanta Magazine. This is an important pattern: when
	possible, it's extremely helpful if Anki is used in service to
	some personal creative project.
      </p>

      <p>
	It's tempting instead to use Anki to stockpile knowledge
	against some future day, to think &ldquo;Oh, I should learn
	about the geography of Africa, or learn about World War II, or
	[&hellip;]&rdquo;. These are goals which, for me, are
	intellectually appealing, but which I'm not emotionally
	invested in.  I've tried this a bunch of times. It tends to
	generate cold and lifeless Anki questions, questions which are
	hard to connect to, and where it's hard to really, deeply
	internalize the answers. The problem is somehow in that
	initial idea I &ldquo;should&rdquo; learn about these things:
	intellectually, it seems like a good idea, but I've little
	emotional commitment.
      </p>

      <p>
	By contrast, when I'm reading in support of some creative
	project, I ask much better Anki questions.  I find it easier
	to connect to the questions and answers emotionally. I simply
	care more about them, and that makes a difference.  So while
	it's tempting to use Anki cards to study in preparation for
	some (possibly hypothetical) future use, I strongly advise
	against it. If you can, it's much better to find a way to use
	Anki as part of some creative project.
      </p>
      
	
    <h3>Using Anki to do shallow reads of papers</h3>
    
    <p>
      Most of my Anki-based reading is much shallower than my read of
      the AlphaGo paper. Rather than spending days on a paper, I'll
      typically spend 10 to 60 minutes. Here's a few notes on some
      patterns I've found useful in shallow reading.
    </p>

    <p>
      I usually do such reading as part of the background research for
      some project. I will find a new article (or set of articles),
      and typically spend a few minutes assessing it. Does the article
      seem likely to contain substantial insight or provocation
      relevant to my project &ndash; new questions, new ideas, new
      methods, new results?  If so, I'll usually spend roughly 10 to
      60 minutes reading it.
    </p>

    <p>
      This doesn't mean reading every word in the paper. Rather, I'll
      add to Anki questions about the core claims and core questions
      of the paper. It's particularly helpful to extract Anki
      questions from the abstract, introduction, conclusion, figures,
      and figure captions. Typically I will extract anywhere from 5 to
      20 Anki questions from the paper. It's usually a bad idea to
      extract fewer than 5 questions &ndash; doing so tends to leave
      the paper as a kind of isolated orphan in my memory.  Later I
      find it difficult to feel much connection to those
      questions. Put another way: if a paper is so uninteresting that
      it's not possible to add 5 good questions about it, it's usually
      better to add no questions at all.
    </p>

    <p>
      One failure mode of this process is if you Ankify misleading
      work. Many papers contain wrong or misleading statements, and if
      you commit such items to memory, you're actively making yourself
      stupider.
    </p>

    <p>
      How to avoid Ankifying misleading work?
    </p>

    <p>
      As an example, let me describe how I Ankified a recent paper I
      read. It's a paper by the economists Benjamin Jones and Bruce
      Weinberg*<span class="marginnote">* Benjamin F. Jones and Bruce
      A. Weinberg, <a href="assets/Jones2011a.pdf">Age Dynamics in
      Scientific Creativity</a>, Proceedings of the National Academy
      of Sciences (2011).</span>, which studies the ages at which
      scientists make their greatest discoveries. I should say at the
      outset: I have no reason to think the paper is misleading! But
      it's also worth being cautious.  As an example of that caution,
      one of the questions I added to Anki was: &ldquo;What does Jones
      2011 claim is the average age at which physics Nobelists made
      their prizewinning discovery, over 1980-2011?&rdquo; (Answer: 48).
      Another variant question was: &ldquo;Which paper claimed that
      physics Nobelists made their prizewinning discovery at age 48,
      over the period 1980-2011?&rdquo; (Answer: Jones 2011).  And so
      on.
    </p>

    <p>
      Such questions qualify the underlying claim: we now know it was
      a claim made in Jones 2011, and that we're relying on the
      quality of Jones and Weinberg's data analysis. In fact, I
      haven't examined that analysis carefully enough to regard it as
      a fact that the average age of those Nobelists is 48. But it is
      certainly a fact that their paper claimed it was 48. Those are
      different things, and the latter is the right thing to Ankify.
    </p>

    <p>
      If I'm particularly concerned about the quality of the analysis,
      I may add one or more questions about what makes such work
      difficult, e.g.: &ldquo;What's one challenge in determining the
      age of Nobel winners at the time of their discovery, as
      discussed in Jones 2011?&rdquo; Good answers include: the
      difficulty of figuring out which paper contained the
      Nobel-winning work; the fact that publication of papers is
      sometimes delayed by years; that sometimes work is spread over
      multiple papers; and so on. Thinking about such challenges
      reminds me that if Jones and Weinberg were sloppy, or simply
      made an understandable mistake, their numbers might be off.
      Now, it so happens that for this particular paper, I don't
      expect the analysis will be far off. And so I didn't Ankify any
      such question.  But it's worth being careful in framing
      questions so you're not misleading yourself.
    </p>
    
    <p>
      Another useful pattern while reading papers is Ankifying
      figures. For instance, here's a graph from Jones 2011 showing
      the age of physics Nobelists when they made their discovery:
    </p>

    <center>
      <img src="assets/Jones_figure2011a.png"/>
    </center>
    
    <p>
      I have an Anki question which simply says: &ldquo;Visualize the
      graph Jones 2011 made of the age at which physics Nobelists make
      their prizewinning discovery&rdquo;. The answer is the image
      shown above, and I count myself as successful if my mental image
      is roughly along those lines. I could deepen my engagement with
      the graph, by adding questions such as: &ldquo;In Jones 2011's
      graph of physics prizewinning discoveries, what is the peak
      probability of great achievement by age 40 [i.e., the highest
      point in the blue line in the graph above]?&rdquo; (Answer:
      about 0.8.)  Indeed, one could easily add dozens of interesting
      questions about this graph. I haven't done that, because of the
      time commitment associated to such questions. But I do find the
      broad shape of the graph fascinating, and it's also useful to
      know the graph exists, and where to consult it if I want more
      details.
    </p>

    <p>
      I said above that I typically spend 10 to 60 minutes Ankifying a
      paper, with the duration depending on my judgment of the value
      I'm getting from the paper. However, if I'm learning a
      tremendous amount, and finding it interesting, I keep reading
      and Ankifying. Really good resources are worth investing time
      in. But most papers don't fit this pattern, and you quickly
      saturate. If you feel you could easily find something more
      rewarding to read, switch over. It's worth deliberately
      practicing such switches, to avoid building a counter-productive
      habit of completionism in your reading. It's nearly always
      possible to read deeper into a paper, but that doesn't mean you
      can't easily be getting more value elsewhere.  It's a failure
      mode to spend too long reading unimportant papers.
    </p>

    <p>
      The exception to this rule is when I'm new to a field. A paper
      may not be very good, but it may use many important techniques
      common to the field. Because those techniques are new to me, I
      find myself Ankifying lots of associated material.
    </p>

      <p>
	This pattern is okay, in moderation. For one thing, those
	techniques are likely to show up in multiple papers, so it
	doesn't much matter when I Ankify them. With that said, if I
	find this pattern occurring repeatedly, it usually means I
	need to refocus on truly key papers, and not get so bogged
	down in less important papers.
    </p>

    <h3>Syntopic reading using Anki</h3>
    
      <p>
	I've talked about how to use Anki to do shallow reads of
	papers, and rather deeper reads of papers. There's also a
	sense in which it's possible to use Anki not just to read
	papers, but to &ldquo;read&rdquo; the entire research
	literature of a field.  Here's how I do it.
      </p>

      <p>
	You might suppose the foundation would be a shallow read of a
	large number of papers. In fact, it's the opposite: to really
	grok an unfamiliar field, you need to engage deeply with key
	papers &ndash; papers like the AlphaGo paper. What you get
	from deep engagement with important papers is more significant
	than any single fact or technique: you get a sense for what a
	powerful result in the field looks like. It helps you imbibe
	the healthiest norms and standards of the field. It helps you
	internalize how to ask good questions in the field, and how to
	put techniques together. You begin to understand what made
	something like AlphaGo a breakthrough &ndash; and also its
	limitations, and the sense in which it was really a natural
	evolution of the field. Such things aren't captured
	individually by any single Anki question. But they begin to be
	captured collectively by the questions one asks when engaged
	deeply enough with key papers.
      </p>

      <p>
	So, to get a picture of an entire field, I usually begin with
	a truly important paper, ideally a paper establishing a result
	that got me interested in the field in the first place. I do a
	thorough read of that paper, along the lines of what I
	described for AlphaGo. Later, I do thorough reads of other key
	papers in the field &ndash; ideally, I read the best 5-10
	papers in the field. But, interspersed, I also do shallower
	reads of a much larger number of less important (though still
	good) papers. That typically means anywhere from tens to
	hundreds of such papers.
      </p>

      <p>
	You may wonder why I don't just focus on only the most
	important papers. Part of the reason is mundane: it can be
	hard to tell what the most important papers are. Shallow reads
	of many papers can help you figure out what the key papers
	are, without spending too much time doing deeper reads of
	papers that turn out not to be so important. But there's also
	a culture that one imbibes reading the bread-and-butter papers
	of a field: a sense for what routine progress looks like, for
	the praxis of the field. That's valuable too, especially for
	building up an overall picture of where the field is at, and
	to stimulate questions on my own part. Indeed, while I don't
	recommend spending a large fraction of your time reading bad
	papers, it's certainly possible to have a good conversation
	with a very bad paper. Stimulus is found an unexpected places.
      </p>

      <p>
	Over time, this is a form of what Mortimer Adler and Charles
	van Doren dubbed <em>syntopic
	reading</em>*<span class="marginnote">* In their marvelous
	&ldquo;How to Read a Book&rdquo;: Mortimer J. Adler and
	Charles van Doren, &ldquo;How to Read a Book: The Classic
	Guide to Intelligent Reading&rdquo; (1972)</span>. I build up
	an understanding of an entire literature: what's been done,
	what's not yet been done. I start to identify open problems,
	questions that I'd personally like answered, but which don't
	yet seem to have been answered. I identify tricks,
	observations that seem pregnant with possibility, but whose
	import I don't yet know. And, sometimes, I identify what seem
	to me to be field-wide blind spots. I add questions about all
	these to Anki as well. In this way, Anki is a medium
	supporting my creative research. It has some shortcomings as
	such a medium, since it's not designed with supporting
	creative work in mind &ndash; it's not equipped for lengthy,
	free-form exploration inside a scratch space. But even without
	being designed in such a way, it's helpful as a creative
	support.
      </p>
      
    <p>
      I've been describing how I use Anki to learn subjects which are
      largely new to me.  By contrast, with a subject I already know
      well, my curiosity and my model of the subject are often already
      so strong that it's rather easier to integrate new facts. I
      still find Anki useful, but it's most useful in new areas.  The
      great English mathematician John Edensor Littlewood
      wrote*<span class="marginnote">* In &ldquo;Littlewood's
      miscellany&rdquo;, edited by Béla Bollobás (1986).</span>:
    </p>

    <blockquote>
      I have tried to learn mathematics outside my fields of interest;
      after any interval I had to begin all over again.
    </blockquote>

    <p>
      This captures something of the immense emotional effort I used
      to find required to learn new areas. Without a lot of drive, it
      was extremely difficult to make a lot of material in a new field
      stick. Anki does a great deal to solve that problem. In a sense,
      it's an emotional prosthetic, actually helping create the drive
      I need to achieve understanding. It doesn't do the entire job on
      its own &ndash; as I remarked earlier, it's very helpful to have
      other commitments (like a creative project, or people depending
      on me) to help create that drive.  Nonetheless, Anki helps give
      me a sense that I can simply <em>decide</em> I'm going to read
      deeply into a new area, and retain and make sense of what I
      learn. This seems to work for almost all areas of conceptual
      understanding*<span class="marginnote">* There are many types of
      motor skills and problem-solving skills I haven't tried using
	Anki for, and I'm not sure if it could be adapted.</span>.
    </p>

    <p>
      One surprising consequence of reading in this way is how much
      more enjoyable it becomes. I've always enjoyed reading, but
      starting out in a challenging new area was a real slog, and I
      was often bedeviled by doubts that I would ever really get into
      the area. That doubt, in turn, made it less likely that I would
      succeed. Now I have confidence that I can just go into a new
      field and quickly attain a good, relatively deep understanding,
      an understanding that will be durable. That confidence often makes
      reading exceedingly pleasurable.
    </p>


    <h3>More patterns of Anki use</h3>


    <p>
      Having looked at the use of Anki for reading technical papers,
      let's return to general patterns of use.
    </p>

    <p>
      <strong>Make most Anki questions and answers as atomic as
      possible:</strong> That is, both the question and answer express
      just one idea. As an example, when I was learning the Unix
      command line, I originally had a question: &ldquo;How to create
      a soft link from <code>linkname</code>
      to <code>filename</code>?&rdquo; The answer was: &ldquo;<code>ln
      -s filename linkname</code>&rdquo;. Unfortunately, I routinely
      got this question wrong.
    </p>

    <p>
      The solution was to break the question into two pieces. One
      piece was: &ldquo;What's the basic command and option to create
      a Unix soft link?&rdquo; Answer: &ldquo;<code>ln -s
      &hellip;</code>&rdquo;. And the second piece was: &ldquo;When
      creating a Unix soft link, in what order do <code>linkname</code> and
      <code>filename</code> go?&rdquo; Answer: &ldquo;<code>filename
	linkname</code>&rdquo;.
    </p>

    <p>
      Breaking this question into more atomic pieces turned a question
      I routinely got wrong into two questions I routinely got
      right*<span class="marginnote">* An even more atomic version
      would be to break the first question into &ldquo;What's the Unix
      command to create a link?&rdquo; and &ldquo;What's the option to
      the <code>ln</code> command to create a soft link?&rdquo; In
      practice, I've known for years that <code>ln</code> is the
      command to create a link, and so this wasn't
      necessary.</span>. Most of all: when I wanted to create a Unix
      soft link in practice, I knew how to do it.
    </p>

    <p>
      I'm not sure what's responsible for this effect. I suspect it's
      partly about focus.  When I made mistakes with the combined
      question, I was often a little fuzzy about where exactly my
      mistake was. That meant I didn't focus sharply enough on the
      mistake, and do didn't learn as much from my failure. When I
      fail with the atomic questions my mind knows exactly where to
      focus.
    </p>

    <p>
      In general, I find that you often get substantial benefit from
      breaking Anki questions down to be more atomic. It's a powerful
      pattern for question refactoring.
    </p>

    <p>
      Note that this doesn't mean you shouldn't also retain some
      version of the original question. I still want to know how to
      create a soft link in Unix, and so it's worth keeping the
      original question in Anki. But it becomes an integrative
      question, part of a hierarchy of questions building up from
      simple atomic facts to more complex ideas.
    </p>

    <p>
      It's tempting to add many such integrative questions. But
      ideally you should be able to derive the answers from your more
      atomic knowledge. And so my rule is to focus mostly on adding
      atomic questions, and to only include integrative questions when
      I believe I'll be using those particular integrations often.
    </p>

    <p>
      Incidentally, just because a question is atomic doesn't mean it
      can't involve quite complex, high-level concepts. Consider the
      following question, from the field of general relativity:
      &ldquo;What is the <em>dr<sup>2</sup></em> term in the
      Robertson-Walker metric?&rdquo; Answer:
      <em>dr<sup>2</sup>/(1-kr^2)</em>. Now, unless you've studied
      general relativity that question probably seems quite
      opaque. It's a sophisticated question, assuming you know what
      the Robertson-Walker metric is, what <em>dr<sup>2</sup></em> means, what
      <em>k</em> means, and so on. But conditional on that background
      knowledge, it's quite an atomic question and answer.
    </p>

    <p>
      One benefit of using Anki in this way is that you begin to
      habitually break things down into atomic questions. This sharply
      crystallizes the distinct things you've learned. Personally, I
      find that crystallization satisfying, for reasons I (ironically)
      find difficult to articulate. But one real benefit is that later
      I often find those atomic ideas can be put together in ways I
      didn't initially anticipate. And so it's well worth going to the
      trouble.
    </p>

    <p>
      <strong>Avoid orphan questions:</strong> Suppose you're reading
      online and stumble across a great article about the grooming
      habits of the Albanian giant mongoose, a subject you never
      previously knew you were interested in, but which turns out to
      be fascinating. Pretty soon you've Ankified 5 to 10
      questions. That's great, but my experience suggests that in a
      few months you'll likely find those questions rather stale and
      disconnected, and frequently get them wrong. I believe the
      reason is that those questions are too far from my other
      interests, and I've lost the context that made me interested.
    </p>

    <p>
      I call these <em>orphan questions</em>, because they're not
      closely related to anything else in my memory. It's not bad to
      have a few orphan questions in Anki &ndash; it can be difficult
      to know what will turn out to be only of passing interest, and
      what will grow into a substantial interest, connected to your
      other interests. But if a substantial minority of your questions
      are orphans, that's a sign you should concentrate more on
      Ankifying questions related to your main creative projects, and
      cut down on Ankifying tangential material.
    </p>

    <p>
      It's particularly worth avoiding lonely orphans: single
      questions that are largely disconnected from everything
      else. Suppose, for instance, I'm reading an article on a new
      subject, and I learn an idea that seems particularly useful. I
      make it a rule to never put in one question. Rather, I try to
      put at least two questions in, preferably three or more. That's
      usually enough that it's at least the nucleus of a bit of useful
      knowledge. If it's a lonely orphan, inevitably I get the
      question wrong all the time, and it's a waste to have entered it
      at all.
    </p>
      
    <p>
      <strong>Use one big deck:</strong> Anki allows you to organize
      cards into decks and subdecks. Some people use this to create a
      complicated organizational structure. I used to do this, but
      I've gradually*<span class="marginnote">* It's gradual because
      questions sometimes need to be rewritten due to the changed
      context. For instance, both my Emacs and Unix command line decks
      had very similar questions, along the lines of: &ldquo;How to
      delete a word?&rdquo; Those questions need to be rewritten,
      e.g. as: &ldquo;In Emacs, how to delete a word?&rdquo; (This, by
      the way, may seem a strange question for a long-time Emacs user
      such as myself. In fact, I've used Anki to help me change the
      way I delete words in Emacs, which is why I have an Anki
      question on the subject. I have made a bunch of improvements to
      my Emacs workflow this way.)</span>  merged my decks and
      subdecks into one big deck. The world isn't divided up into
      neatly separated components, and I believe it's good to collide
      very different types of questions. One moment Anki is asking me
      a question about the temperature chicken should be cooked
      to. The next: a question about the JavaScript API. Is this
      mixing doing me any real good? I'm not sure. But I don't think
      it does any harm, and hope it is creatively stimulating, and
      helps me apply my knowledge in unusual contexts.
    </p>

    <p>
      <strong>Don't share decks:</strong> I'm often asked whether I'd
      be willing to share my Anki decks. I'm not. Very early on I
      realized it would be very useful to put personal information in
      Anki. I don't mean anything terribly personal &ndash; I'd never
      put deep, dark secrets in there. Nor do I put anything requiring
      security, like passwords. But I do put some things I wouldn't
      sling about casually.
    </p>

    <p>
      As an example, I've a (very short!) list of superficially
      charming and impressive colleagues who I would never work with,
      because I've consistently seen them treat other people
      badly. It's helpful to Ankify some details of that treatment, so
      I can clearly remember why that person should be avoided. This
      isn't the kind of information that is right to spread casually:
      I may have misinterpreted the other person's actions, or have
      misunderstood the context they were operating in. But it's
      personally useful for me to have in Anki.
    </p>

    <p>
      <strong>Construct your own decks:</strong> The Anki site
      has <a href="https://ankiweb.net/shared/decks/">many shared
      decks</a>, but I've found only a little use for them. The most
      important reason is that making Anki cards is an act of
      understanding in itself.  That is, figuring out good questions
      to ask, and good answers, is part of what it means to understand
      a new subject well. To use someone else's cards is to forgo much
      of that understanding.
    </p>

    <p>
      I believe the act of constructing the cards actually helps with
      memory. Memory researchers have repeatedly found that the more
      elaborately you encode a memory, the stronger the memory will
      be. By elaborative encoding, they mean essentially the richness
      of the associations you form.
    </p>

    <p>
      For instance, it's possible to try to remember as an isolated
      fact that 1962 was the year the first telecommunications
      satellite, Telstar, was put into orbit. But a better way of
      remembering it is to relate that fact to others. For instance, I
      personally find it fascinating that Telstar was put into orbit
      the year <em>before</em> the introduction of ASCII, arguably the
      first modern digital standard for communicating text. Humanity
      had a telecommunications satellite before we had a digital
      standard for communicating text! Finding that kind of connection
      is an example of an elaborative encoding.
    </p>

    <p>
      The act of constructing an Anki card is itself nearly always a
      form of elaborative encoding. It forces you to think through
      alternate forms of the question, to consider the best possible
      answers, and so on. I believe this is true for even the most
      elementary cards. And it certainly becomes true if you construct
      more complex cards, cards relating the basic fact to be
      remembered to other ideas (like the Telstar-ASCII link),
      gradually building up a web of richly interrelated ideas.
    </p>

    <p>
      With all that said, there are some valuable deck-sharing
      practices. For instance, there are communities of medical
      students who find value in sharing and sometimes collaboratively
      constructing decks*<span class="marginnote">* See
      the <a href="https://www.reddit.com/r/medicalschoolanki/">MedicalSchoolAnki
      subreddit</a>, which contains frequent discussion of the best
      decks, how to use them, as well as ever-changing canon of best
      decks to use for different purposes. See also the paper: Michael
      Hart-Matyas <em>et
      al</em>, <a href="assets/Hart-Matyas2018.pdf">Twelve tips for
      medical students to establish a collaborative flashcard
      project</a>, Medical Teacher (2018).</span>. Perhaps there is
      value in using a very high-quality deck constructed by someone
      else. If nothing else, you may learn good new patterns for
      questions, patterns that will help you construct better
      questions in future. I've also found value in
      shared <a href="https://ankiweb.net/shared/info/685421036">art
      decks</a>, asking questions such as who painted a particular
      painting. But for deeper kinds of understanding, I've found
      shared decks of minimal use.
    </p>

    <p>
      <strong>95% of the value of Anki comes from 5% of the
      features:</strong> I don't use most of Anki's features. Anki has
      ways of auto-generating cards, of tagging cards, a plugin
      ecosystem, and much else. In practice, I rarely use any of these
      features. My cards are always one of two types: the majority are
      simple question and answer; a substantial minority are what's
      called a <em>cloze</em>: a kind of fill-in-the-blanks test. For
      instance, I'll use clozes to test myself on favorite quotes:
    </p>

    <blockquote>
      &ldquo;if the personal computer is truly a __ then the use of it
      would actually change the __ of an __", __, __&rdquo; (Answer:
      new medium, thought patterns, entire civilization, Alan Kay,
      1989).
    </blockquote>

    <p>
      Clozes can also be used to pose questions not involving quotes:
    </p>
    
    <blockquote>
      The Adelson illusion is also known as the ___ illusion. (Answer:
      checker-shadow)
    </blockquote>

    <p>
      Why not use more of Anki's features? Part of the reason is that
      I get an enormous benefit from just the core features.
      Furthermore, learning to use this tiny set of features well has
      required a lot of work. A basketball and hoop are simple pieces
      of equipment, but you can spend a lifetime learning to use them
      well. Similarly, basic Anki practice can be developed
      enormously. And so I've concentrated on learning to use those
      basic features well.
    </p>

    <p>
      I know many people who try Anki out, and then go down a rabbit
      hole of figuring out how to learn as many features as possible
      so they can use it &ldquo;efficiently&rdquo;. Usually, they're
      chasing 1% improvements. Often, those people ultimately give up
      Anki as &ldquo;too difficult&rdquo;, which seems to be a synonym
      for &ldquo;I got nervous I wasn't using it
      perfectly&rdquo;. This is a pity. As I mentioned above, Anki
      offers something like a 20-fold improvement over (say) ordinary
      flashcards. And so they're giving up a 2,000% improvement
      because they were worried they were missing a few final 5%, 1%
      and (in many cases) 0.1% improvements. This kind of rabbit hole
      seems to be especially attractive to programmers.
    </p>

    <p>
      For this reason, when someone is getting started I strongly
      advise: don't use any advanced features, and don't install any
      plugins. Don't, in short, come down with a bad case of
      programmer's efficiency disease. Learn how to use Anki for basic
      question and answer, and concentrate on exploring new patterns
      within that paradigm. That'll serve you far better than any
      number of hours spent fiddling around with the features. Then,
      if you build a regular habit of high-quality Anki use, you can
      start experimenting with more advanced features.
    </p>

    <p>
      <strong>The challenges of using Anki to store facts about
      friends and family:</strong> I've experimented with using Anki
      to store (non-sensitive!) questions about friends and family. It
      works well for things like &ldquo;Is [my friend] a vegan?&rdquo;
      But my use quickly ran aground on thornier questions. For
      instance, suppose I'd talked with a new friend about their kids,
      but never met those kids. I might put in questions like
      &ldquo;What is the name of [my friend's] eldest child?&rdquo;
      Or, if we'd chatted about music, I might put in: &ldquo;What is
      a musician [my friend] likes?&rdquo;
    </p>

    <p>
      This kind of experiment is well intentioned. But posing such
      questions always leaves me feeling uncomfortable. It seems too
      much like faking interest in my friends. There's a pretty strong
      social norm that if you remember your friends' taste in music or
      their kids' names, it's because you're really interested in that
      friend. Using a memory aid feels somehow ungenuine.
    </p>

    <p>
      I've talked with several friends about this. Most have told me
      the same thing: they appreciate me going to so much trouble in
      the first place, and find it charming that I'd worry so much
      about whether it was ungenuine. So perhaps it's a mistake to
      worry.  Nonetheless, I have trouble doing it. I have adopted it
      for less personal stuff &ndash; things like people's food
      preferences. And maybe over time I'll use it for storing more
      personal facts. But for now I'm taking it slow.
    </p>

    <p>
      <strong>Process versus declarative memory:</strong> There's a
      big difference between remembering a fact and mastering a
      process.  For instance, while you might remember a Unix command
      when cued by an Anki question, that doesn't mean you'll
      recognize an opportunity to use the command in the context of
      the command line, and be comfortable typing it out. And it's
      still another thing to find novel, creative ways of combining
      the commands you know, in order to solve challenging problems.
    </p>

    <p>
      Put another way: to really internalize a process, it's not
      enough just to review Anki cards. You need to carry out the
      process, in context. And you need to solve real problems with
      it.
    </p>

    <p>
      With that said, I've found the transfer process relatively
      easy. In the case of the command line, I use it often enough
      that I have plenty of opportunities to make real use of my
      Ankified knowledge of the command line. Over time, that
      declarative knowledge is becoming knowledge I routinely use in
      context. That said, it'd be good to better understand when the
      transfer works and when it doesn't. Even better would be a
      memory system that integrates into your actual working
      environment. For instance, it could query you on Unix commands,
      while placing you at an actual command line. Or perhaps it would
      ask you to solve higher-level problems, while at the command
      line.
    </p>

    <p>
      I've tried one experiment in this vein: miming the action of
      typing commands while I review my Anki cards. But my subjective
      impression was that it doesn't work so well, and it was also
      quite annoying to do. So I stopped.
    </p>

    <p>
      <strong>Getting past &ldquo;names don't matter&rdquo;:</strong>
      I'm a theoretical physicist by training. There is a famous story
      in physics, told by Richard Feynman, dismissing the value of
      knowing names. As a child, he was out playing in a field with a
      know-it-all kid. Here's what happened, in Feynman's telling:
    </p>

    <blockquote>
	One kid says to me, &ldquo;See that bird?  What kind of bird is
	that?&rdquo;

	<br><br>I said, &ldquo;I haven't the slightest idea what kind
	of a bird it is.&rdquo;

	<br><br>He says, &ldquo;It'a brown-throated thrush. Your
	father doesn't teach you anything!&rdquo;

	<br><br>But it was the opposite. He [Feynman's father] had
	already taught me: &ldquo;See that bird?&rdquo; he
	says. &ldquo;It's a Spencer's warbler.&rdquo; (I knew he
	didn't know the real name.)  &ldquo;Well, in Italian, it's
	a <em>Chutto Lapittida</em>. In Portuguese, it's a <em>Bom da
	Peida</em>&hellip; You can know the name of that bird in all
	the languages of the world, but when you're finished, you'll
	know absolutely nothing whatever about the bird! You'll only
	know about humans in different places, and what they call the
	bird. So let's look at the bird and see what
	it's <em>doing</em> &mdash; that's what counts.&rdquo; (I
	learned very early the difference between knowing the name of
	something and knowing something.)
    </blockquote>

    <p>
      Feynman (or his father) goes on to a thoughtful discussion of
      real knowledge: observing behavior, understanding the reasons
      for it, and so on.
    </p>

    <p>
      It's a good story. But it goes too far: names do matter. Maybe
      not as much as the know-it-all kid thought, and they're not
      usually a deep kind of knowledge. But they're the foundation
      that allows you to build up a network of knowledge.
    </p>

      <p>
	This trope that names don't matter was repeatedly drilled into
	me during my scientific training. When I began using Anki, at
	first I felt somewhat silly putting questions about names for
	things into the system. But now I do it enthusiastically,
	knowing that it's an early step along the way to
	understanding.
      </p>

    <p>
      Anki is useful for names of all kinds of things, but I find it
      particularly helpful for non-verbal things. For instance, I put
      in questions about artworks, like: &ldquo;What does the artist
      <a href="https://www.emilyhare.co.uk/">Emily Hare's</a> painting
      <em>Howl</em> look like?&rdquo; Answer:
    </p>

    <center>
    <img src="assets/EmilyHareHowl.png">
    </center>

    <p>
      I put that question in for two reasons. The main reason is that
      I like to remember the experience of the painting from time to
      time. And the other is to put a name to the painting. If I
      wanted to think more analytically about the painting &ndash;
      say, about the clever use of color gradients &ndash; I could add
      more detailed questions. But I'm actually pretty happy just
      committing the experience of the image to memory.
    </p>

    <p>
      <strong>What do you do when you get behind?</strong> Anki
      becomes challenging when you get behind with cards. If you skip
      a day or two &ndash; or fifty &ndash; the cards begin to back
      up. It's intimidating to come back to find you have 500 cards to
      review in a day. Even worse, if you fall out of the Anki habit,
      you can get a very long way behind. I largely stopped using Anki
      for a 7-month period, and came back to thousands of backlogged
      cards.
    </p>

    <p>
      Fortunately, it wasn't that hard to catch up. I set myself
      gradually increasing quotas (100, 150, 200, 250, and eventually
      300) of cards per day, and worked through those quotas each day
      for several weeks.
    </p>

    <p>
      It wasn't too hard, but, frankly it really was somewhat
      demoralizing and discouraging. It'd be better if Anki had a
      &ldquo;catch up&rdquo; feature that would spread the excess
      cards over the next few weeks in your schedule. But it
      doesn't. In any case, this is a gotcha, but it's possible to
      address.
    </p>

      <p>
	<strong>Using Anki for books, videos, seminars, conversations,
	  events, and places:</strong> Nearly everything I've said
	  about Ankifying papers applies also to other
	  resources. Here's a few tips.
      </p>

      <p>
	For seminars and conversations with colleagues I find it
	helpful to set quotas. For instance, for seminars I try to
	find at least three high-quality questions to Ankify. For
	conversations, at least one high-quality question to
	Ankify. I've found that setting quotas helps me pay more
	attention, especially during seminars. (I find it much
	easier <em>a priori</em> to pay attention in one-on-one
	conversation.)
      </p>

      <p>
	I'm more haphazard about videos, events, and places. It'd be
	good to, say, systematically Ankify 3-5 questions after going
	on an outing or to a new restaraunt, to help me remember the
	experience. I do this sometimes. But I really haven't been
	that systematic.
      </p>

      <p>
	I tend to Ankify in real time as I read papers and books. For
	seminars, conversations, and so on I prefer to immerse myself
	in the experience. Instead of getting out Anki, I will quickly
	make a mental (or paper) note of what I want to Ankify. I then
	enter it into Anki later. This requires a bit of discipline;
	it's one reason I prefer to set a small quota, so that I
	merely have to enter a few questions later, rather than
	dozens.
      </p>
	
      <p>
	One caution is with books: reading an entire book is a
	substantial commitment, and adding Anki questions regularly
	can slow you down a lot. It's worth keeping this in mind when
	deciding how much to Ankify. Sometimes a book is so dense with
	great material that it's worth taking the time to add lots of
	questions. But unmindfully Ankifying everything in sight is a
	bad habit, one I've occasionally fallen into.
      </p>

      <p>
	What you Ankify is not a trivial choice: Ankify things that
	serve your long-term goals. In some measure we become what we
	pay attention to, so we must be careful what we pay attention
	to*<span class="marginnote">* With apologies to Kurt Vonnegut,
	who said: &ldquo;We are what we pretend to be, so we must be
	careful about what we pretend to be.&rdquo;.</span>. This is
	always true, but Anki makes it especially true.
      </p>

    <p>
      With all that said, one fun pattern is to go back to my old,
      pre-Anki notes on books, and to Ankify them. This can often be
      done quickly, and gives me a greater return on the time I've
      invested in now mostly-forgotten
      books*<span class="marginnote">* Friends sometimes complain that
      many books are over-padded essays.  I've sometimes wondered if
      one benefit of such padding is that it enforces a kind of spaced
      repetition, along Anki-like lines, since it means readers take
      some weeks to read the book.  This is perhaps an inefficient way
      to memorize the main points of the book, but may well be better
      than having no memory of the book at all.</span>.
    </p>

    <p>
      Something I haven't yet figured out is how to integrate Anki use
      with note taking for my creative projects. I've found I
      certainly can't replace note-taking with Anki &ndash; it's too
      slow, and for many things a poor use of my long-term memory. On
      the other hand, there are also a lot of benefits to using Anki
      for important items &ndash; fluid access to memory is at the
      foundation of so much creative thought. In practice, I find
      myself instinctively and unsystematically doing some things as
      notes, others as Anki questions, and still other things as
      both. Overall, it works okay, but my sense is that it could be a
      lot better if I applied more systematic thought and
      experimentation. Part of the problem is that I don't have a very
      good system for note-taking, period!  If I worked more on that,
      I suspect the whole thing would get a lot better. Still, it
      works okay.
    </p>

    <h3>Example: Using Anki to learn APIs</h3>
    
    <p>
      As the discussion of the command line above suggested, I find
      Anki exceptionally helpful for learning new APIs.  Here's the
      pattern which works for me, and a few warnings about patterns
      that don't work.
    </p>

    <p>
      It begins with me realizing that there's some API I'd like to
      use in a project. Now, some of the time, I just want to use the
      API a little &ndash; say, 50-100 lines, or perhaps a bunch of
      1-10 line code snippets. In that case it's a mistake to worry
      too much about really learning the API. You're better off just
      winging it, adapting snippets from elsewhere, consulting the
      docs as needed.
    </p>

    <p>
      But suppose I know I will use the API more seriously in a
      project.  For instance, for my
      essay <a href="http://cognitivemedium.com/tat/">Thought as a
      Technology</a> I wanted to build some prototypes using 3d
      graphics, and I decided I would need to learn the basics of
      the <a href="https://threejs.org/">three.js</a> Javascript
      library.
    </p>

    <p>
      One very tempting failure mode is to think &ldquo;Oh, I should
      master the API first&rdquo;, to dive into tutorials or the
      documentation. Apart from a (very!) quick skim of a tutorial or
      the documentation, that's a mistake. A much better approach is
      to find a small, functioning piece of code that does something
      related to the project I intend to build. It doesn't need to be
      similar to the whole project, but it should ideally implement
      one or two common features, and be no more than a few hundred
      lines long. I get that code running, then I can start making
      small tweaks, adding bits of functionality I need, taking out
      bits that I don't, and trying to understand and even improve the
      existing code.
    </p>

    <p>
      The great thing about this is that I need only change 1 to 5
      lines of code at a time, and it still runs. But I can also see
      meaningful progress toward my goals, and that's tremendously
      exciting. To use a metaphor from machine learning, it's like
      doing gradient descent in the space of meaningful, exciting
      projects.
    </p>

    <p>
      Of course, while doing this, I'll constantly be looking up
      things in the docs, on StackOverflow, and so on. I'll also be
      reading and understanding pieces of the code I've started
      from. It's tempting to try to Ankify all of this, but it's a
      mistake: it takes too much time, and you Ankify too much that
      later turns out to be pointless.  However, when something seems
      like it's clearly a central concept, or you know you'd like to
      reuse it often, it's worth adding to Anki. In this way, you
      gradually build up a knowledge base of things you can use in
      real, live projects. And, slowly, you start to get better and
      better.
    </p>

    <p>
      Once you're making real progress on your project, and confident
      you've made a good choice of API, then it makes sense to work
      through a tutorial. Indeed, don't just find one tutorial &ndash;
      if you can, find several. Dip a little into each, and try to
      find out one that leaps out as &ldquo;Oh, I'm learning quickly
      from this.&rdquo;. And then, work through it. I do Ankify at
      this stage, but try to keep it relatively light. It's tempting
      (and possible) to Ankify everything, but that slows you down
      enormously. It's much better to only Ankify material
      you <em>know</em> you'll need repeatedly. The usual sign of this
      is that you can already see you need it right now, at the
      current stage of your project.  That goes double if you can see
      you'll need it repeatedly in the future. On the first pass, I
      tend to be conservative, preferring to Ankify less
      material. Then, once I've gone through it once, I go back over
      it again, this time Ankifying everything I'm likely to need
      later. This second pass is actually quite rapid &ndash; usually
      much faster than the first pass &ndash; but I find that on the
      second pass I have much more context, and my judgment about
      what to Ankify tends to be much better.
    </p>

    <p>
      You can continue doing this, bouncing back and forth between
      your project and using Anki as you work through tutorials and
      documentation. In the very earliest stages you'll spend quite a
      bit of time in the docs, just getting basic syntax right. After
      that you should spend most of your time on your project. But I
      find it helpful to spend a substantial fraction of time on
      Ankifying good-quality material, particularly material closely
      related to the project.  This means tutorials, documentation, as
      well as material that comes up while reading code &ndash; code
      from others, and even code you've written yourself. Indeed, I've
      occasionally Ankified the APIs for code I've personally written,
      if they're likely to be useful in the future. Just because I
      wrote something doesn't mean I'll automatically remember it in
      future!
    </p>

    <p>
      So: don't jump into Ankifying tutorials and so on straight
      away. Wait, and do it in tandem with serious work on your
      project. I must admit, part of the reason I advise this is
      because I find the advice hard to take myself, and I always
      regret not following it. I start a new project, think &ldquo;Oh,
      I need such-and-such an API&rdquo;, and then dive into a
      tutorial, spending hours on it. But I struggle and struggle and,
      frankly, make very slow progress. Until I remember to start with
      some working code, and immediately find things are working much
      better. I then swear to never use the tutorial-first approach
      again. Unfortunately, in practice, it's quite seductive.
    </p>

    <p>
      Another failure mode is to think &ldquo;Oh, I might want to
      learn such-and-such an API one day, so I should start adding
      cards, just in case.&rdquo;
    </p>

    <p>
      Don't do this.
    </p>

    <p>
      It's tempting, especially for a certain kind of person &ndash;
      the kind of person who likes to stockpile knowledge against some
      (largely theoretical) day when they'll get to use it. But you
      will learn far more (and far more quickly) if you're
      simultaneously using the API seriously in a project.  Using the
      API to create something new helps you identify what is truly
      important to remember from the API. And it also &ndash; this is
      just my speculation here &ndash; sends a signal to your brain
      saying &ldquo;this really matter&rdquo;. And while it's just
      speculation, I think this helps your memory quite a bit. And so,
      seriously, if you're tempted to do highly speculative
      Ankification, please just don't. And if you find yourself
      starting, stop.
    </p>

    <p>
      A partial failure mode that I've repeatedly noticed is orphan
      APIs. That is, I'll start to use a new API for a project. I'll
      Ankify some material along the way. Then the project will
      finish, and I won't quickly have another project that uses the
      same API. Later on, when I'm no longer using the API, and have
      no immediate plans to, I'll sometimes find the cards a little
      strange. My mind won't engage &ndash; sometimes, there's even a
      slight rejection, a sort of half-conscious &ldquo;why am I
      learning this useless stuff?&rdquo; I just no longer find the
      cards as interesting as when I was using the API actively.
    </p>

    <p>
      This is a difficult situation. I think the best rule of thumb is
      that if it seems likely that you're not going to use the API
      again, then delete the cards when they come up. But if it seems
      highly likely you'll want to use the API in the next year or so,
      keep them in the deck. It's not a perfect solution, since it
      means you really do slightly disconnect from the cards. But it's
      an okay compromise solution.
    </p>

    <h3>Anki as a virtuoso skill and method of understanding</h3>

    <p>
      Considered as a computer program, Anki is incredibly simple. It
      lets you enter text or other media, and then shows you the media
      later in a cued way, with the schedule changing in a way
      determined by your responses.
    </p>

    <p>
      That's it.
    </p>

    <p>
      And yet I've just written more than 10,000 words on how to use
      it. Although simple, it's an incredibly powerful tool. And, like
      many tools, it requires skill to use well.  What's more, that's
      a skill you can develop, over time. What would it take to
      develop truly virtuosic skills with Anki?
    </p>

    <p>
      One common misconception about Anki is that it's just for
      memorizing very simple raw facts, things like vocabulary items
      and basic definitions. But as we've seen, it's possible to use
      Anki in a much more sophisticated way. My questions about
      AlphaGo began with &ldquo;How large is a Go board?&rdquo; And
      ended up with high-level conceptual questions about the design
      of the AlphaGo systems &ndash; questions too complex to make
      sense here, but about subjects such as how AlphaGo avoided
      over-generalizing from training data, what the shortcomings of
      using convolutional neural networks might have been, and so on.
    </p>

    <p>
      Anki isn't just a tool for memorizing simple facts.
    </p>

    <p>
      It's a tool for understanding almost
      anything*<span class="marginnote">* Andy Matuschak first pointed
      out to me that this view is unusual, and differs greatly from
      the conventional view of Anki. It was also through conversations
      with Andy that I understood that Anki use could be a virtuoso
      skill.</span>.
    </p>

    <p>
      Many of the observations I've made about how to use Anki are
      implicitly about a theory of what it means for me to
      understand. Break things up into atomic facts. Build rich
      hierarchies of interconnections. Don't put in orphan
      questions. Patterns for how to engage with reading material,
      patterns for question types, patterns for the kinds of things
      you'd like to memorize. And so on.
    </p>

    <p>
      As one's theory of how to understand improves, so does one's
      theory of Anki. And vice versa. They're not the same thing. But
      Anki skills are a concrete instantiation of your theory of how
      you understand. And Anki use can be a valuable prod to better
      develop that theory.
    </p>

    <h3>Memory as one of the keys to cognition</h3>
    
    <p>
      Let me finish the direct discussion of Anki by mentioning a
      speculative idea about how Anki enables understanding.
    </p>

        <span class="marginnote">The core assertion underlying this essay
    is really that memory is far, far more important than people think
    to cognition. In particular, it's the basis on which people build
    up the chunks (recoding) that are the basis of truly effective
    action. It's far more important to problem solving than people
    think. It's far more important to creativity than people think
    ("speed of associative thought", in Littlewood's phrase). It's at
    the absolute foundation of understanding. Basically, spaced
    repetition is very special, because it makes absolutely everything
    else about your cognition much more effective. It's a way of
    getting Fermi's magic memory.
      <br><br>Rewrite the start. Memory sometimes gets a bad
    rap. People will disparage rote memory. <br><br>Need to settle on
    a broad name for the approach. Should call it spaced
    repetition. Emphasize that it's rather incomplete - more is going
    on. But we need a name.<br><br>It'd be good to identify and
    emphasize the core beliefs motivating this chapter. One is
    above. Another is that spaced repetition is good for much more
    advanced types of understanding than just lists of countries, etc,
    of the conventional type.
    </span>

    <p>
      In the 1970s, Herbert Simon and his collaborators XXX did a
      series of studies of how people acquired expertise, focusing
      particularly on chess.  They found that world-class chess
      experts saw the board differently to beginners. A beginner would
      see &ldquo:a pawn here, a rook there&rdquo;, and so on, a series
      of individual pieces. Master-level players saw much more
      elaborate &ldquo;chunks&rdquo;: combinations of pieces that they
      recognized as a unit, and were able to reason about at a higher
      level of abstraction than the individual pies. The Masters'
      training was helping them learn how to see and reason about
      those higher-level chunks.
    </p>

    <p>
      I suspect that Anki doesn't just help you form long-term
      memories. But in domains were you build up great depth in
      memories (and, perhaps, you also apply them creatively), your
      mind starts to automatically form higher-level chunks. And
      these, in turn, help you form true expertise.
    </p>

    <p>
      Why does chunking matter to expertise? Let me give you my
      working theory [XXX - Simon may have done the same, or de Groot
      in their 1978 book]. It's speculation, basically a story &ndash;
      as far as I know, this hasn't been validated by cognitive
      scientists.  But I find it useful. I'll describe it in the
      context of mathematics, since that's an area where I've talked
      with people at all ranges of ability, including some of the
      world's best mathematicians.
    </p>

    <p>
      Many people's model of first-rate mathematicians is that they
      are astoundingly bright, with very high IQs, and the ability to
      deal with very complex ideas in their mind. In particular, a
      common model is that their smartness gives them the ability to
      deal with very complex ideas. Basically, they have a
      higher-horsepower engine.
    </p>

    <p>
      It's true that top mathematicians are usually very bright. But
      here's a different explanation of what's going on. It's that,
      per Simon, many of those people have, through hard work,
      internalized more high-level chunks than I have. And what this
      means is that situations which seem very complex to me actually
      seem very simple to them. So it's not that they necessarily have
      a higher horsepower mind, one capable of dealing with more
      complexity. Rather, their learning has given them better
      chunking abilities, and so situations I see as complex they see
      as simple, and so their mind makes more sense of it.
    </p>

    <p>
      In general, there is a substantial correlation between general
      intellectual ability (IQ) and working memory XXX. The better
      your working memory, the higher your IQ, and vice versa. But if
      you've developed more chunks in some domain, like chess or
      mathematics, then in some regards that is like an increase in
      your working memory in that domain. In particular, someone with
      a lower IQ but more complex chunks may be able to effectively
      reason about more complex situations than someone with a higher
      IQ but less complex chunks.
    </p>

    <p>
      In other words, having more chunks is like getting a higher
      effective IQ in that domain.
    </p>

    <p>
      Now, this is a speculative informal theory (XXX). But I think
      it's a helpful model of what's going on. And I think that part
      of what Anki is doing is speeding up the acquisition of those
      high-level chunks. And that's a way of becoming a much more
      effective thinker in the domains related to those chunks.
    </p>
    
      
    <h3>Principles of long-term memory systems</h3>

    <p>
      How should we build long-term memory systems? Anki is an
      extremely encouraging step. Can we improve on it? Or can we
      perhaps build systems which use similar ideas to serve other
      needs? In this section, I'll take a brief look at a few key
      principles that can be used in the design of long-term memory
      systems.  There are three core ideas I emphasize: distributed
      practice; the testing effect; and the structuring of human
      attention.
    </p>

    <p>
      <strong>Distributed practice:</strong> Suppose you're introduced
      to someone at a party, and they tell you their name. Of course,
      how well you remember their name later depends on how long it is
      until you need to recall it.  If you're paying attention, and
      their name isn't too unusual, you'll almost certainly remember
      their name 20 seconds later. But you're more likely to have
      forgotten their name in an hour, and more likely still to have
      forgotten their name in a month.
    </p>

    <p>
      That is, memories decay. This isn't news!  But the great German
      psychologist Hermann Ebbinghaus had the clever idea of studying
      memory decay systematically and
      quantitatively*<span class="marginnote">Hermann
      Ebbinghaus, <a href="http://psychclassics.yorku.ca/Ebbinghaus/index.htm">Memory:
      A Contribution to Experimental Psychology</a> (1885).</span>. In
      particular, he was interested in <em>how</em> quickly memories
      decay, and what caused the decay. To study this, Ebbinghaus
      memorized strings of nonsense syllables &ndash; things like
      &ldquo;fim&ldquo; and &ldquo;pes&rdquo;, and recorded how well
      he retained those syllables after different time intervals.
    </p>

    <p>
      Ebbinghaus found that the probability of correctly recalling an
      item declined (roughly) exponentially with time.  Today, this is
      called the <em>Ebbinghaus forgetting curve</em>:
    </p>

    XXX

    <p>
      What determines the steepness of the curve, i.e., how quickly
      memories decay? In fact, the steepness depends on many
      things. For instance, it may be steeper for more complex or less
      familiar concepts. You may find it easier to remember a name
      that sounds similar to names you've heard before: say, Richard
      Hamilton, rather than Suzuki Harunobu. So they'd have a
      shallower curve.  Similarly, you may find it easier to remember
      something visual than verbal. Or something verbal rather than a
      motor skill. And if you use more elaborate ways of remembering
      &ndash; mnemonics, for instance, or just taking care to connect
      an idea to other things you already know &ndash; you may be able
      to flatten the curve out.
    </p>

    <p>
      Ebbinghaus's exponential decay only occurs when you don't recall
      the item. Suppose you're introduced to a person at a party,
      don't think about their name again for 20 minutes, then need to
      bring it to mind to introduce them to someone else. Immediately
      after that, your probability of recall will again be very high.
      Ebbinghaus's research suggested that the probability will decay
      exponentially after the re-test, but the rate of decay will be
      slower. In fact, subsequent re-tests slow the decay still more:
    </p>

    XXX

    <p>
      This gradual increase in decay time underlies the design of Anki
      and similar memory systems. It's why Anki uses gradually
      expanding time periods between testing.
    </p>

    <p>
      These phenomena are part of a broader set of ideas which have
      been extensively studied by scientists. There are several
      related terms used for this set of phenomena, but we'll use the
      phrase &ldquo;distributed practice&rdquo;, meaning practice
      which is distributed in time, ideally in a way designed to
      maximally promote retention.
    </p>

    <p>
      <strong>On the use of the scientific literature:</strong> Since
      Ebbinghaus, there's been thousands of studies of different
      variations of distributed practice. In some sense, these studies
      have taught us a great deal about the behavior of long-term
      memory. It's tempting to jump into that literature, and to use
      it as a guide to the design of memory systems.
    </p>

    <p>
      We are, in fact, going to learn much from that literature. But
      before we do that, I want to make some high-level remarks about
      the limitations of the scientific literature as a guide to the
      development of systems.
    </p>

    <p>
      It's true that scientists have done a tremendous number of
      studies of distributed practice. In some sense we do
      &ldquo;know&rdquo; a lot. But on the other hand, many very basic
      questions about distributed practice remain poorly understood.
    </p>

    <p>
      We don't understand in detail why exponential decay of memory
      occurs, or when that model breaks down. We don't understand what
      determines the rate of decay, and why it varies for different
      types of memories. We don't understand why the decay takes
      longer after subsequent recalls. And we have little
      understanding of the best way of expanding the inter-study
      intervals.
    </p>

    <p>
      Of course, there are many partial theories to answer these and
      other basic questions. But there's no single, powerful, broadly
      accepted general theory. And so in that sense, we know little
      about distributed practice, and are probably decades (if not
      more) away from a reasonably full understanding.
    </p>

    <p>
      To illustrate this point concretely, let me mention just one
      example: there are times when our memories don't decay, but get
      better over time, even when we're not aware of explicit acts of
      recall.  Informally, you have may have noticed this in your own
      life. In XXX the psychologist William James made the
      tongue-in-cheek observation that XXX. This effect was
      experimentally verified in a XXX study of XXX Oehrn, who showed
      XXX. Unfortunately, while subsequent experiments have confirmed
      this result, the picture remains poorly understood. It depends
      sensitively on the type of material being memorized &ndash;
      Oehrn used XXX &ndash; on the exact time intervals, and many
      other variables.  Now, obviously this contradicts the Ebbinghaus
      exponential forgetting curve that I described above. In
      practice, a pretty good heuristic is that the Ebbinghaus curve
      holds, but there are exceptions, usually over limited times, and
      for very specific types of materials.
    </p>

    <p>
      I don't mention this to undermine your belief in the Ebbinghaus
      model. But rather to caution you: memory is complicated, we
      don't understand many of the big picture questions well, and we
      should be careful before we put too much faith in any given
      model.
    </p>

    <p>
      With all that said: the basic effects underlying distributed
      practice are real, large, and have been confirmed by many, many
      experiments. Effects like that discovered by Oehrn are real, but
      they're much less important by comparison.
    </p>

    <p>
      This places us in a curious situation: we have enough
      understanding of memory to conclude that a system like Anki
      should help a lot. But many of the choices you need to make in
      the design of such a system must be made in an
      <em>ad hoc</em> way, guided by intuition and unconfirmed
      hypotheses. The experiments in the scientific literature
      do <em>not</em> yet justify those design choices. The reason is
      that those experiments are mostly not intended to address those
      questions. They'll focus on specific types of information to
      memorize. Or they'll focus on relatively short periods of time
      &ndash; memorization over a day or a week, not for years. This
      doesn't mean such work isn't helping us build a better theory of
      memory. It just means it's not answering the questions designers
      need to build systems.
    </p>

    <p>
      As a consequence, systems designers must look elsewhere: to
      informal experiments and theories. Anki, for example, uses a
      spacing algorithm developed by Piotr Wozniak on the basis of
      personal experimentation. Although Wozniak has published
      a <a href="https://www.supermemo.com/english/publicat.htm">number
      of papers</a>, they are informal reports, not contributions to
      the conventional cognitive science literature, since they don't
      abide by its norms. In some sense, this is not satisfactory: we
      don't understand what a good spacing schedule is to use. But a
      system has to use some schedule, and so designers do the best
      they can. This works much better than naive approaches, but over
      the long run it'd be good to have an approach based on a
      detailed theory of how human memory
      works*<span class="marginnote">Worse, you can get a kind of
      system authority effect, where people take choices made in
      systems very seriously, sometimes conferring on <em>ad hoc</em>
      choices an authority they don't deserve.</span>.
    </p>

    <p>
      Now, one response to this is to say that you should design
      scientifically, and have good experimental evidence for all
      design choices. I've heard this used as a criticism of the
      designers of systems such as Anki, that they make too
      many <em>ad hoc</em> guesses, not backed by a systematic
      scientific understanding.
    </p>

    <p>
      But what are they supposed to do? Wait 50 or 100 years, until
      those answers are in? Give up design, and become memory
      scientists for the next 30 years, so they can answer the
      questions they need answered.
    </p>

    <p>
      This isn't the way design works, nor the way it should work.
    </p>

    <p>
      If you waited until all the evidence was in, no-one would ever
      design anything. In practice, what you want is imaginative, bold
      design, exploring many ideas, but inspired and informed by what
      is known scientifically. Ideally, alongside this there would be
      a (necessarily much slower) feedback loop, whereby design
      choices would suggest questions about memory, and scientific
      experiments, and the improved understanding of memory would
      suggest new avenues for design:
    </p>

    XXX - feedback loop.

    <p>
      Of course, That's easy to say. But it's not at all easy to achieve.
    </p>

    <p>
      The human-computer interaction community has tried to achieve
      it. But I don't think it's worked very well. As we'll discuss
      more in Chapter XXX, they've given up a lot of boldness and
      imagination in design. At the same time, they're not doing
      full-fledged cognitive science either &ndash; they're not really
      working toward a detailed understanding of the mind. Frankly, I
      think they've actually taken the worst of both worlds, not the
      best.
    </p>

    <p>
      In any case, we'll come back to this later: the relationships
      between design and cognitive science and how to get it
      right. It's a core problem, and one that is not trivial to
      resolve.
    </p>

    <p>
      <strong>The testing effect:</strong> In school, we usually think
      of &ldquo;studying&rdquo; and &ldquo;testing&rdquo; as two very
      different activities. Anki upends this: it makes testing into a
      form of studying; indeed, you're being tested over and over (and
      over!)  again. In fact, numerous studies have shown that being
      tested on material is a much more efficient way of learning
      material than is spending the same amount of time studying. This
      is known as the <em>testing effect</em>. Systems such as Anki
      which use the testing effect are said to involve <em>active
      recall</em>, as opposed to the <em>passive recall</em> that
      takes place when someone merely rereads material, rather than
      being actively tested on it.
    </p>

    <p>
      An influential demonstration of the testing effect is in a 2006
      paper by the psychologists Henry Roediger and Jeffrey
      Karpicke*<span class="marginnote">* Henry L. Roediger, III, and
      Jeffrey
      D. Karpicke, <a href="assets/Roediger2006a.pdf">Test-Enhanced
      Learning: Taking Memory Tests Improves Long-Term Retention</a>
      (2006)</span>. In one of their experiments, Roediger and
      Karpicke ask participants to study some simple essays. To do
      this, the participants were divided into three groups. One group
      read over (studied) the essays in four different sessions. We'll
      denote this group SSSS &ndash; study, study, study, study. A
      second group (SSST) read over the essays in the first three
      sessions, and then took a test (T) in the fourth session.  And a
      third group (STTT) read over the essays in the first session,
      and then took tests in the final three sessions. The length of
      the study and test sessions were arranged so that participants
      in all three groups engaged with the essay for the same total
      time.
    </p>

    <p>
      A week later, participants in all three groups were tested
      again, to see how well they could recall key ideas from the
      essays. The SSSS group recalled 40% of the ideas, the SSST group
      recalled about 56%, and the STTT group did best of all: 61%.
      Remarkably, this held even though participants got no feedback
      on how they'd done on intermediate tests. It seemed taking the
      tests promoted recall even without feedback, and repeated
      testing resulted in participants recalling about half as many
      items again as did repeated studying. (When experiments along
      similar lines are done <em>with</em> feedback, the testing
      effect usually continues to hold, and is sometimes stronger XXX
      check.)
    </p>

    <p>
      In another variation of their experiment, Roediger and Karpicke
      didn't wait a week to give the final test. Instead, they gave it
      just 5 minutes after the fourth session. In that experiment,
      participants in the SSSS group did best (83%), with the SSST
      group next (78%), and the STTT group worst (71%). In other
      words, over the short-term merely re-reading the essays was
      better than being tested. But repeated testing helped much more
      over the longer-term. Somehow it was promoting the formation of
      longer-term memories. XXX - something here bothers me.
    </p>

    <p>
      After completion of the four sessions, Roediger and Karpicke
      asked participants how well they thought they'd remember the
      material in a week.
    </p>

    <p>
      Can you guess what they found?
    </p>

    <p>
      In fact, people's self-perception was exactly the reverse of how
      the final tests actually turned out.  Members of the SSSS group
      thought they would recall much <em>better</em> than members of
      the SSST group, who in turn thought they'd recall somewhat
      better than members of the STTT group. Being tested made people
      less confident of their memory, but actually improved it more
      than re-reading.
    </p>

    <p>
      The testing effect has been widely studied. As with distributed
      practice, the picture that emerges has a lot of nuance. The
      strength of the testing effect can vary with the type of
      material, with the age of participants, with the type of test,
      and with many other variables.
    </p>

    <p>
      Still, the basic underlying phenomenon is clear: being tested on
      material usually produces significantly better memories.  What's
      more, although it hasn't been as thoroughly studied, there are
      also several studies suggesting participants feel as though they
      learn less from testing. It's as though while studying in the
      conventional way they're deluding themselves about how well
      things are going, while testing rudely interrupts those
      delusions &ndash; but ultimately produces longer-lasting
      memories.
    </p>

    <p>
      One challenge for systems based on active recall is that many
      people have principled objections to testing. I don't just mean
      the natural dislike that comes with the feeling of failure that
      comes when you don't know the answer to a question. I mean
      general arguments against the notion of testing itself, the kind
      of argument that have led many people to advocate for removing
      testing from schools.
    </p>

    <p>
      A common line of argument is that testing kills the joy of
      learning, turning something that should be its own intrinsic
      reward &ndash; learning &rdquo; into something motivated by
      extrinsic rewards, such as recognition for exceptional
      performance.
    </p>

    <p>
      I'm sympathetic to such arguments. But they don't apply to
      personal memory systems. You aren't doing Anki for an extrinsic
      reward. Rather, it's something you do for yourself, for an
      intrinsic reward: a better memory of things you're interested
      in.
    </p>

    <p>
      And so I believe many common arguments against testing don't
      apply to personal memory systems such as Anki. Of course, such
      arguments might apply if such systems were imposed compulsorily
      in the classroom. But that's more a statement about classroom
      culture than it is anything to do with personal memory systems.
    </p>

    <p>
      <strong>Systems to structure human attention:</strong> I've been
      focusing on important ideas from cognitive science. But there
      are also important ideas which don't come from cognitive
      science. Rather, they come from the designers and
      builders*<span class="marginnote">* I'm mostly going to say
      &ldquo;designers&rdquo; from now on, although in many cases the
      designer is also a programmer who actually builds the
      system.</span> who builds systems that enable people to take
      advantage of these facts about human memory.
    </p>

    <p>
      In 2014, <em>The New York Times</em> science journalist Benedict
      Carey published the book &ldquo;How We Learn&rdquo;. It's a
      popular science book, with extended discussion of distributed
      practice, the test effect, and many other ideas.  Carey frames
      the book as a kind of self-help, bringing you up-to-date on
      cognitive science research, with the goal of helping you be more
      effective in your learning.
    </p>

    <p>
      It's a good book, and an excellent, thoughtful review of some of
      the main ideas in the cognitive science of
      learning. Unfortunately, Carey has little to say about how to
      take advantage of these ideas. It's one thing to understand that
      distributed practice is much better than cramming. It's quite
      another thing to actually systematically act on this
      understanding. Indeed, Carey's and other discussions of
      distributed practice often frame it as though people are making
      a choice between cramming and distributed practice. But that's
      not right. For all but the most organized people, it's not so
      much that you're choosing between cramming and distributed
      practice. Rather, you're choosing between cramming and no study
      at all.
    </p>

    <p>
      These points apply more broadly to the entire cognitive science
      literature. It's one thing to know how memory works. It's quite
      another to develop a really good, easily usable system that
      makes it possible to take advantage of that understanding of
      memory. Developing such systems is a difficult skill, a skill
      very different to studying memory.
    </p>

    <p>
      And so it is only natural that the systems that enable us to act
      on the insights of cognitive scientists have been built by
      systems designers, not by cognitive scientists.
    </p>

    <p>
      Anki, for example, was developed by Damien Elmes, a professional
      programmer who works fulltime on the project.
    </p>

    <p>
      Anki is a descendant of the
      program <a href="https://www.supermemo.com/en/frontpage">SuperMemo</a>,
      developed by a researcher named Piotr Wozniak who has devoted
      much of his life to developing systems for spaced repetition. In
      some sense, Wozniak is a combined researcher and designer. But
      his research is not at all research in the conventional sense of
      cognitive science. Rather, it's devoted almost entirely to
      improving SuperMemo and related systems. Looking through
      his <a href="http://super-memory.com/english/publicat.htm">publications</a>
      it's striking how different they are from typical papers in
      cognitive science.
    </p>

    <p>
      Prior to SuperMemo, the science writer Sebastian Leitner
      developed a card-based system for learning foreign languages. It
      was not computerized, and somewhat cumbersome, requiring the
      user to manually move cards from one part of the filing system
      to another. Still, it became extremely popular in Germany.
    </p>

    <p>
      None of these people are cognitive scientists in the
      conventional sense. Rather, they are system designers and
      builders.
    </p>

    <p>
      In general, it's notable how little direct impact cognitive
      scientists have had on how people think. This is because
      cognitive science is about studying how people actually think,
      not (for the most part) prescribing how they should think, or
      about building systems to help them think more effectively. This
      is not a criticism of cognitive science. Rather, it's just an
      acknowledgment that the norms of cognitive science do not
      favor cognitive scientists building or studying systems.
    </p>

    <p>
      When I point this out, sometimes people suggest that if only the
      norms of cognitive science were to change, cognitive scientists
      would start building systems. This underestimates just how
      difficult systems design and building is. Someone with the
      skills to build a magnificent theory of human memory may know
      very little about how to build systems that will enable memory
      to operate at its best. That's because building effective
      systems &ndash; even prototype systems &ndash; is very, very
      hard work to do well. We'll come back to this line of
      questioning in Chapter XXX.
    </p>

    <p>
      This is, in part, why I believe we need a field of human
      augmentation. That field will take input from cognitive
      science. But it will fundamentally be a design science, oriented
      toward asking questions about what kind of systems we can build,
      and then building, all the way from prototype to large-scale
      deployment.
    </p>


    <a name="Anki_analysis"></a>
    <h2>Appendix: analysis of Anki study time</h2>
      
    <p>
      Here's a ballpark analysis of the effort required to study an
      Anki card for recall over 20 years &ndash; what we might
      reasonably consider lifetime recall. Note that the analysis is
      sensitive to the detailed assumptions made, so the time
      estimates shouldn't be taken too seriously. Nonetheless, it's
      useful to get a sense of the times involved.
    </p>

    <p>
      When a card is initially entered, Anki requires reviews after
      just 1 minute and then 10 minutes. After those reviews the
      interval between reviews rises substantially, to 1 day. The
      interval expansion rate after that may vary a
      little*<span class="marginnote">* The reason is that Anki allows
      you to specify that you found a card &ldquo;easy&rdquo; or
      &ldquo;hard&rdquo; when you review it, in addition to the
      generic &ldquo;good&rdquo; (meaning you got it right) or
      &ldquo;again&rdquo; (meaning you got it wrong). Those additional
      options vary the exact rate of interval expansion. In practice,
      I nearly always choose &ldquo;good&rdquo;, or tell Anki that I
      got the card wrong.</span>, but for my cards the typical
      expansion rate is by a factor of about 2.4 for each successful
      review. That means that successful reviews will raise the
      interval to 2.4 days, then to 2.4 * 2.4 = 6.76 days, and so on.
      On average, I get about 1 in 12 cards wrong, so by the 12th card
      we're up to about 2.4<sup>9</sup> = 2,642 days between
      reviews. Note that we raise to the 9<sup>th</sup> power rather
      than the 12<sup>th</sup> power, because it's not until the third
      repetition of a card that the interval reaches 1 day.
    </p>

    <p>
      If you sum those intervals all up, it suggests the typical time
      between failed reviews is about 12 years.  Note, however, that I
      haven't been using Anki for nearly that long, and this estimate
      may be over-optimistic.  We can get a lower bound on the time
      between failures by observing that my mean interval between card
      reviews is already 1.2 years.  To achieve an interval of 1.2
      years requires about 0.9 years of successful prior reviews, so
      on average my cards involve at least 2.1 years between
      failures. However, the real number may be much higher, since
      there's no reason to assume my next review on most of those
      cards is going to fail.  So let's say that a conservative
      estimate is a mean time between failures of between 4 and 7
      years.
    </p>

    <p>
      If we assume the mean time between failures is 4 years, then
      over 20 years that means 5 failures, and reviewing 5 failures *
      10 reviews per period = 50 times, for a total of 50 * 8 seconds
      = 400 seconds, or about 7 minutes.
    </p>

    <p>
      If instead we assume the mean time between failures is 7 years,
      then over 20 years that means roughly 3 failures, and reviewing
      3 failures * 11 reviews per period = 33 times, for a total of 33
      * 8 seconds &approx; 260 seconds, or about 4 minutes.
    </p>

    <p>
      Note that in Anki's model a failure resets the review interval
      back to 10 minutes, then to 1 day, 2.4 days, and so on. In
      practice, that seems much too conservative.  After one or two
      failures with a card I usually catch on, and it would be better
      if Anki wasn't so draconian in resetting the review schedule. A
      better review schedule would reduce the total study time, and I
      wouldn't be surprised if a commitment of &tilde;2 minutes was
      possible, for an average card.
    </p>

    <h3>Acknowledgments</h3>

    <p>
      I became intrigued with Anki in considerable part due to the
      writing
      of <a href="https://www.gwern.net/Spaced-repetition">Gwern
      Branwen</a>, <a href="https://sasha.wtf/anki-post-1/amp/">Sasha
      Laundy</a>, and <a href="https://sivers.org/srs">Derek
      Sivers</a>.  Thanks to Mason Hartman, Andy Matuschak, and Kevin
      Simler for many useful conversations about this essay.
    </p>

    <p>
      Ask for review: Gwern. Luke. 
    </p>
    
      testing 


    <script src="assets/adjust_marginnotes.js" type="text/javascript">
    </script>
    
  </body>
</html>
