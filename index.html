<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>How to Augment Human Intelligence?</title>
    <link rel="stylesheet" type="text/css" href="style.css">
    <link rel="stylesheet" type="text/css" href="js/demo/demo.css">
  </head>

  <body>
    <div id="header">
      <h1>How to Augment Human Intelligence?</h1>
      <p>
	<a href="http://michaelnielsen.org">Michael Nielsen</a> &nbsp;
	/ &nbsp; <a href="https://ycr.org">Y Combinator Research</a> &nbsp;
	/ &nbsp; August 2018
      </p>

    </div>

    <div id="container">
    <p>
      Human language is a miracle of culture and biology. While many
      species of animal can think, human language provides a substrate
      for a qualitatively more powerful kind of thought. Language is a
      <em>cognitive technology</em>, an invented external artifact
      which expands the range and power of the thoughts we can think.
    </p>

    <p>
      Language is just one of many cognitive technologies humans have
      invented. Mathematics, maps, and musical notation are all
      cognitive technologies in a similar sense: they are external
      artifacts, invented by human beings, which we can internalize
      and use to think new thoughts, thoughts that would otherwise be
      beyond us.
    </p>

    <p>
      In the 1960s, Douglas Engelbart and J. C. R. Licklider realized
      that computers can be used as a kind of meta-medium to invent
      new cognitive technologies. In particular, imaginative interface
      designers can invent fundamental new cognitive technologies that
      carry meaning in new ways, and so expand the range of our
      thinking. In Engelbart's marvellous phrase, we can use computers
      to <em>augment human intellect</em>.
    </p>

    <p>
      This vision has led to many successes. It influenced almost
      every element of modern computing, helping lead to graphical
      user interfaces, modern word processing, online collaboration,
      and many other important ideas. It also decisively influenced
      later researchers, such as Alan Kay and others at Xerox PARC,
      and entrepreneurs such as Steve Jobs, with his vision of
      computers as a &ldquo;bicycle for the mind&rdquo;.
    </p>

    <p>
      In this essay I examine the past, present, and future of this
      vision of augmenting human intellect. How much have computers
      helped augment humans to date? What are the most powerful
      patterns of augmentation we've discovered? What principles
      underly those patterns? What opportunities remain to transform
      human cognition? And, in particular: what ambitious visions of
      the future of computing can we hold today?
    </p>

    <p>
      In answering these questions, it's tempting to set a modest bar,
      to identify opportunities to create a new company or product, or
      to improve efficiency at standard cognitive tasks.  These are
      valuable goals, and we'll consider them, but we'll also find
      value in aspiring toward much higher standards of augmentation.
    </p>

    <p>
      Might it be possible to use computers to make a change in human
      thinking as large or larger than the invention of language?
      This perhaps seems ludicrous: after all, language utterly
      transformed our cognition. But it's also a useful lens,
      motivating very different questions and ideas than &ldquo;Can we
      build a startup?&rdquo; or &ldquo;Can we improve efficiency at
      [standard task] by 30 percent?&rdquo; Furthermore, it's
      historically been a useful lens. The world wide web is a
      derivative of Ted Nelson's original idea
      of <em>hypertext</em>. And, as the name implies, hypertext
      didn't arise from thinking about nifty startup ideas; it arose
      from wondering whether the nature of text itself could be
      changed.
    </p>

    <p>
      Another very high standard comes from Alan Kay. In discussing
      the impact of computers on children, he noted that &ldquo;Where
      some people measure progress in answer-right / test or
      tests-passed / year, we are more interested in
      &lsquo;Sistine-Chapel Ceilings / Lifetime&rsquo;.&rdquo; What is
      the ultimate capacity of computers to enable creative work?
      What is their capacity to enable discovery? Is it true, as Kay
      has argued, that &ldquo;the real computer revolution hasn't
      happened yet&rdquo;, and that it's possible to think not in
      terms of million- or billion-dolllar companies, but in terms of
      transformational trillion-dollar industries?  Again, this is a
      high standard and hard to meet. But it has the benefit of
      motivating different questions and ideas than lower standards.
    </p>

    <p>
      You may object that this is all silly. But computers have only
      been widely available for 40 years. Previous revolutions in how
      humans think &ndash; associated to events like the introduction
      of the printing press, the invention of science, and the
      invention of cartography &ndash; often took centuries. In the
      case of the invention of language, it took millennia. And so it
      seems possible that we're still in the early days, that Alan Kay
      is correct that the real computer revolution is yet to happen.
    </p>
      
    <p>
      This essay is unusually personal.  I've spent most of my life
      obsessed by the idea of using systems &ndash; especially
      computers &ndash; to improve the way I and others think.  But I
      must admit to frustration. I believe progress has been far
      slower than it could have been, that we can experiment with much
      more radical ways of augmenting human intelligence, and this
      will result in more rapid progress. I've spent the past three
      years working fulltime on the problem. As a beginner to
      professional work in the area, I've been gradually understanding
      pieces of the problem. But having attained some basic
      competence, in this essay I want to take an extended look at the
      big picture, to ask what, if anything, we can do to speed things
      up, and to develop an optimistic vision of the future of
      computing. I must admit to some pessimism in setting out. But I
      have to try.
    </p>

    <p>
      It's tempting to make this a general survey of the future of
      computing. After all, almost everything done with computers
      affects human intellect.  Companies and ideas as diverse as
      Reddit, the block chain, 4Chan, Uber, and AirBNB all affect how
      humans behave, and their capabilities; at least in some sense
      they're all affecting human intellect.  If &ldquo;affecting
      human intellect&rdquo; is our standard, then this essay could
      slide into surveying everything that's shiny and fun in
      computing. That's not a terrible project &ndash; indeed, it's
      not a bad approximation to the way many venture capitalists and
      technology writers operate &ndash; but it's unlikely to produce
      the focus which results in truly novel and deep ideas. We're
      going to keep coming back to the same fundamental question: what
      are the most powerful ideas we can use to help us expand the
      range of thoughts we can think?
    </p>

    <p>
      The essay begins by identifying several powerful patterns for
      augmenting human intelligence.  These provide the context for
      broader questions, and the development of a broader theory of
      augmentation.  Note, however, that at present this document is a
      draft. It's possible &ndash; indeed, I think likely &ndash; that
      during the writing of the draft I will develop good new
      organizing structures. That may require me to reorganize what
      I'm writing in a second draft. For now, though, the rule of
      thumb will be to start with the best ideas I currently have, to
      develop them, to research the other leads I have, and to see
      where I end up. In particular, I'm not going to worry too much
      if I gradually realize that the structure needs to be
      different. I will note those structural ideas down, and come
      back to them when I have a first draft. (The reason is that it's
      easier to assess the structural ideas later on, when you can see
      what you've got.)
    </p>

    <p>
      One challenge in writing a work of synthesis like this essay is
      the many fields it involves. From design to cognitive science to
      artificial intelligence to human-computer interaction to
      semiotics, and others. Of course, I have not mastered all those
      fields. There are certainly important perspectives I've missed,
      and my apologies to those whose work I've failed to adequately
      cite. Nonetheless, I believe there is value in this big-picture
      synthetic view, that it reveals a vision that cannot be obtained
      by working in a more narrowly focused fasion.
    </p>
    
    <h2>Developing new elements of cognition</h2>

    <p>
      Let me begin by showing a rough
      prototype<span class="marginnote">The prototype and some of the
      text which follows are adapted from XXX.</span> for exploring
      the motion of a particle in one dimension, that is, on a line.
      It's aimed at people already familiar with basic physics, in
      particular ideas such as potential and kinetic energy. If you
      don't have that background, I hope the prototype is still
      accessible. And if you've more background in physics, please
      return to the mindframe of a relative beginner. Note that the
      prototype begins with some explanation, before showing an actual
      interface. Here it is:
    </p>

    <p>
      XXX
    </p>

    <p>
      This prototype suggests (though it does not fully flesh out) an
      interface which can be used to think about one-dimensional
      motion. A person who intensively used such an interface would
      strongly internalize the interface's basic elements, things like
      the potential energy, the energy surface, and the plane cutting
      through to reveal the trajectories. Such elements would become a
      powerful new language of thought for the user to reason about
      motion in one dimension. The interface elements would, in fact,
      be new
      <em>elements of cognition</em>.
    </p>

    <p>
      Many of these elements of cognition are truly new, unlike
      anything the user is likely to have seen before: things like the
      act of cutting the energy surface to reveal the trajectories;
      moving the cut up and down to see the trajectories change; the
      way we sweep over the potential to create the energy surface.
      These elements are, at the very least, unusual. And taken
      together, they are unique, unlike any other set of
      representations we use to think about the world. They are not
      just remixes of standard interface elements &ndash; of clickable
      icons, and hyperlinks, and check boxes, and so on. Rather, there
      is some fundamental novelty in these elements.  And, whatsmore,
      they are exceptionally well adapted to the problem of
      understanding one-dimensional motion. In short, they provide a
      novel mental language we can use to think previously unthinkable
      thoughts.
    </p>

    <p>
      This is a common pattern in augmentation: the introduction of
      fundamental new elements of cognition, which can be used to
      expand the range of thoughts we can think:
    </p>

    <p>
      XXX
    </p>

    <p>
      How can we carry out the expansion implied by the diagram above?
      What heuristics can we use to develop fundamental new elements
      of cognition? Let's take a look at a powerful heuristic 
    </p>
    
    
    <h3>Using interfaces to reify powerful ideas about the world</h3>
    
    <p>
      The energy surface prototype concretely reifies
      
      This prototype concretely reifies the principle of conservation
      energy. By this I mean it shows that principle in a manner which
      is simple and vivid and concrete.  In so doing, it converts a
      principle which people often think of as difficult and abstract
      into the natural environment in which they think.  In
      particular, if you constantly see the energy surface before you,
      and manipulate it, then eventually it becomes automatic to see
      and to reason about the trajectories. You are constantly
      immersed in a world in which conservation of energy is
      obviously, inevitably true. And because the principle is so
      powerful, determining everything about the shape of trajectories
      in one dimension, this gives you a powerful new way of thinking
      about the world.
    </p>

    <p>
      Contrast this with the traditional approach to understanding
      one-dimensional motion, in which the principle of conservation
      of energy is written in an algebraic form, as:
    </p>

    <p>
      &frac12; <em>mv<sup>2</sup></em> + <em>U(x)</em> = constant
    </p>

    <p>
      In an expert's hands this is a powerful basis for thinking about
      such systems. We'll return later to consider in detail the
      merits and demerits of this representation. But for now note
      that this equation does not provide us with the same immersive
      quality as the energy surface prototype. Rather, the equation is
      kind of bolted on to our thinking, and we need to remember to
      &ldquo;apply&rdquo; it in any given situation, where
      &ldquo;apply&rdquo; is really a shorthand for several different
      kinds of algebraic manipulation, depending on the task at
      hand. In such a model, conservation of energy is implicit, not
      concrete and explicit.
    </p>

    
    <p>
      The energy surface prototype has a certain uniqueness, even a
      strangeness about it. It does not look like other
      interfaces. It's true that there are elements that are similar
      to things you've previously seen, such as the editing of the
      potential. But many elements are unique to this prototype
      &ndash; the sweeping out of the parabolic curve, the cutting of
      the energy surface to find trajectories, moving the energy up
      and down.  This uniqueness arises because the interface vividly
      expresses a very particular set of relationships: the
      relationships between position and velocity represented
      algebraically as:
    </p>
    
    <p>
      &frac12; <em>mv<sup>2</sup></em> + <em>U(x)</em> = constant
    </p>

    <p>
      Those relationships are almost certainly very <em>different</em>
      to any relationships we've seen expressed in an interface
      before; it's that difference which makes the interface appear
      strange. In a sense, the strangess is a direct reflection of the
      power of the underlying principle to reveal unexpected
      connections.
    </p>

    <p>
      <span class="marginnote">This paragraph is adapted from Carter
      and Nielsen 2017 XXX, which discusses this issue of strangess in
      more depth.</span> Such strangeness violates the conventional
      wisdom that interfaces should be &ldquo;user friendly&rdquo;,
      i.e., simple and immediately useable by novices. That most often
      means the interface is cliched, built from conventional elements
      combined in standard ways. It is not reflecting any deep and
      unexpected relationships. And so it will do little to deepen the
      user's understanding or to change the way they think. For
      mundane tasks that is fine, but for deeper tasks, and for the
      longer term, you want a better interface.
    </p>


    <h3>
      Interface design is difficult. Furthermore, there are intrinsic
      reasons it's hard to understand how difficult it is
    </h3>

    <p>
      My training is as a theoretical physicist, and for about 15
      years I worked as a researcher on quantum mechanics. In popular
      culture, quantum mechanics has a reputation as a difficult
      subject.  Perhaps arrogantly, when I began working on interface
      design I thought it would be easy to pick up.
    </p>

    <p>
      I was wrong. I quickly found it was much more difficult than I
      expected. I would look at the work of the best interface
      designers, and it would seem easy and effortless. Emboldened, I
      would sketch out my own ideas, only to find they seemd to be
      trivial, boring recombinations of existing
      ideas<span class="marginnote">Compare to Feynman's story on
      learning to write</span>. Somehow I was greatly underestimating
      the work of the interface designers.
    </p>

    <p>
      A similar problem bedevils writers. The better someone writes,
      the easier their subject seems. This has the strange consequence
      that if someone explains a subject badly, people sometimes
      admire them for taking on such a difficult subject. But if
      someone else explains the same subject wonderfully well, people
      often think &ldquo;Oh, well, it wasn't such a difficult
      subject&rdquo;.
    </p>

    <p>
      As a writer this is immensely frustrating. It actually
      incentivizes a kind of obscurity, since the more effort you
      apply to a piece, the easier it may appear to a reader. And, in
      many cases, those readers don't notice, but take for granted
      their hard-earned ease. The beautifully lucid writer John
      Kenneth Galbraith once drily noted that &ldquo;I do not put that
      note of spontaneity that my critics like into anything but the
      fifth drat&rdquo;.
    </p>

    <p>
      Interface design suffers from an extreme form
      of this problem. As we've seen with the examples of arabic
      numerals and XXX and XXX, interface design builds the deepest
      principles humans have discovered into the very representations
      we use to think with. This makes trivially easy what used to be
      extremely difficult. And to do that requires an exquisite
      combination of mastery of representation, of design, and of the
      underlying subject matter.
    </p>

    <p>
      <span class="marginnote">This paragraph adapted from Carter and
      Nielsen XXX.</span>At its deepest, interface design is about
      developing the fundamental representations human beings think
      and create with.  This is a problem whose intellectual genesis
      goes back to the inventors of the alphabet, of cartography, and
      of musical notation, as well as modern inventors of new
      representations, such as Descartes, Playfair, Feynman,
      Engelbart, and Kay. It is about designing the very substrate of
      our thoughts, and about inventing new forms of thought. It is
      one of the hardest, most important, and most fundamental
      problems humanity grapples with. And so, no, interface design is
      not easy at all.
    </p>

    <p>
      For me personally, while I began by thinking that interface
      design is easy, as I understood it better, I had repeated
      epiphanies that interface design is far more difficult than I
      previously understood. And now I understand that at its depest,
      interface design is one of the most difficult things humans do,
      certainly far more difficult than something comparatively easy,
      like quantum mechanics.
    </p>

    <p>
      <span class="marginnote">Again, adapted from Carter and Nielsen
      XXX.</span>Despite this challenge, most people greatly
      underestimate the difficulty of interface design. They regard it
      as a simple problem, mostly about making things pretty or
      easy-to-use. In this view, the hard problems lie elsewhere
      &ndash; in coding, or developing new algorithms, or building a
      business, and so on.  This is exacerbated by the fact that in
      many fields being bright is associated with being able to see
      past external forms. And so the brightest people are often
      people who can extract meaning from superficially dull
      content. Many suffer from a kind of representation-blindness,
      regarding the form as unimportant, as though it can be separated
      from the &ldquo;true&rdquo; underlying content.
    </p>

    <p>
      As one instance of this pattern, when I describe my research,
      people often respond: &ldquo;Oh, that sounds like the kind of
      thing <a href="http://worrydream.com">Bret Victor</a>
      does.&rdquo; I respond that I've been deeply influenced by
      Victor's work. And many then reply with some variation on
      &ldquo;Oh, I love his work, it means the world to me&rdquo;, or
      even say that it's &ldquo;changed their life&rdquo;. They then
      ask to show me their ideas inspired by it. Occasionally that
      work is good. But 99 percent of the time time it's boring,
      unoriginal, derivative work. Most of his admirers don't have the
      internalized mental models that allow them to have interesting
      new interface ideas. And so their ideas, while well meant, have
      a shallow quality. What's more, not only do they not have good
      heuristics for interface design, they often know so little that
      they don't even realize this is true.
    </p>

    <p>
      I suspect that what's going on is that Victor's work is so
      beautifully presented that it looks as though what he does is
      effortless. Of course, it's not.  But his admirers look at this
      apparently effortless work, think "Well, I'm smart" and that
      they should be able to do the same with a little effort. But
      they have no idea how difficult the problem is, or how hard they
      need to work to get good at it.  Again, in case you missed it
      the first four times: interface design is hard.
    </p>

    <p>
      Like writing, I believe the only way to really appreciate the
      difficult of interface design is to do it for a long time. Your
      initial attempts will likely be boring and derivative. What's
      more, you are likely to know so little you don't even realize
      they are boring and derivative. But with enough work, you may
      eventually develop fundamental new ideas, ideas that make
      formerly difficult thoughts easy to express. That requires years
      understanding existing interface ideas; it requires heuristics
      to generate new interfaces ideas; and it requires deep subject
      matter familiarity in your desired area. And, like a writer, you
      must keep at it until lightning strikes.
    </p>
    
    <h2>
      What is interface design, then?
    </h2>

    <p>
      It is tempting to think it must be some kind of science, in a
      manner similar to sciences such as physics, chemistry, biology,
      and so on. But this isn't right. To illustrate, consider the
      heuristics for new cognitive technologies that we've been
      discussing. For instance, the idea that if something is vivid
      and unique then that helps make it highly internalizable.
    </p>

    <p>
      Now, such a heuristic is obviously not a law in the usual sense
      of the natural sciences. I've little idea how to reliably
      measure something's &ldquo;vividness&rdquo; or
      &ldquo;uniqueness&rdquo; or its &ldquo;internalizability&rdquo;,
      much less to establish relationships between such quantities.
    </p>

    <p>
      Of course, you could develop a research program in that vein,
      attempting to reliably define and measure such quantities. It'd
      be a valuable research program. But while it would be valuable,
      that's <em>not</em> the program I'm laying out here.
    </p>

    <p>
      My program is to develop and apply heuristics which stimualte
      our imaginations, cuasing us to conjure ideas we would not
      otherwise have. In other words, it's about finding interesting
      new ways of exploring the space I described before:
    </p>

    XXX

    <p>
      Now, this is a difficult criterion. It's vague and hard to
      apply, making it difficult to judge ideas and work. It has many
      of the same problems as judging writing or music or art. Now,
      some writing and music and art really is better. But it's also
      notoriously difficult to reliably make such judgements. As a
      result, those fields tend to be more political and more subject
      to appeals to authority and guru figures. I've done this here,
      with appeals to Alan Kay and Douglas Engelbart and so on. These
      people have, of course, done excellent things, and it's valuable
      to hear their opinion. But without strong evidence, such appeals
      to authority are not good arguments, though they may be &ndash;
      as I have intended &ndash; useful for suggesting interesting
      ideas.
    </p>

    <p>
      Indeed, if you like through pioneering papers, by people like
      Engelbart and Kay, it's striking how many arguments now seem
      erroneous. Fortuantely, that doesn't matter, because the papers
      also contain many very interesting and useful ideas. And that's
      the right criterion to judge by.
    </p>

    <p>
      Now, for someone outside the field it's tempting to look at
      this, throw one's hands up in the air, and declare it all to be
      hopelessly subjective. Indeed, this is the response many
      hard-science types have to softer pursuits, such as art and
      music, to decry them as having no real standards. That's
      understandable, but a bad mistake. We're just going to have to
      do the best we can, remembering that the ultimate goal isn't to
      meet the standards of some guru or past expert. It's to figure
      out the best ways of augmenting human intelligence.
    </p>

    <p>
      If it's not laws in the tradition of the natural sciences that
      we're looking for, what then is the objective of work on
      augmentation? First and foremost, it's extremely imaginative
      ideas for fundamental new elements of cognition. It's heuristics
      to stimulate such ideas, and arguments for and against certain
      types of impact. It's prototypes helping us understand the
      impact of those new elements. And it's products and companies
      making those ideas available to larger groups of people.
    </p>

     

      
    <h2>Acknowledgments</h2>

    <p>
      The opening sentence is a riff on, and homage to, the opening
      sentence of Steven Pinker's &ldquo;The Language Instinct&rdquo;.
    </p>
    </div>
    
  </body>
</html>
